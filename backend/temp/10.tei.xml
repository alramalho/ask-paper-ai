<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/alramalho/grobid-0.6.1/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andras</forename><surname>Jakab</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyvan</forename><surname>Farahani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Kirby</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliya</forename><surname>Burren</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Porz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Slotboom</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Wiest</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levente</forename><surname>Lanczi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Gerstner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc-André</forename><surname>Weber</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Arbel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Ayache</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Buendia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Louis</forename><surname>Collins</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Cordier</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tilak</forename><surname>Das</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Delingette</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Çağatay</forename><surname>Demiralp</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">R</forename><surname>Durst</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Dojat</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senan</forename><surname>Doyle</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joana</forename><surname>Festa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florence</forename><surname>Forbes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezequiel</forename><surname>Geremia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polina</forename><surname>Golland</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotao</forename><surname>Guo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andac</forename><surname>Hamamci</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khan</forename><forename type="middle">M</forename><surname>Iftekharuddin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><surname>Jena</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><forename type="middle">M</forename><surname>John</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ender</forename><surname>Konukoglu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danial</forename><surname>Lashkari</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><forename type="middle">António</forename><surname>Mariz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Meier</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sérgio</forename><surname>Pereira</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Price</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tammy</forename><forename type="middle">Riklin</forename><surname>Raviv</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Syed</forename><forename type="middle">M S</forename><surname>Reza</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ryan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Sarikaya</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Schwartz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoo-Chang</forename><surname>Shin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Silva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Sousa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagesh</forename><forename type="middle">K</forename><surname>Subbanna</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Szekely</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><forename type="middle">M</forename><surname>Thomas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">J</forename><surname>Tustison</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gozde</forename><surname>Unal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flor</forename><surname>Vasseur</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Wintermark</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hye</forename><surname>Dong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binsheng</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darko</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Zikic</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Prastawa</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koen</forename><forename type="middle">Van</forename><surname>Reyes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leemput</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
						</author>
						<title level="a" type="main">The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TMI.2014.2377694</idno>
					<note type="submission">received July 04, 2014; accepted September 01, 2014. Date of publication December 04, 2014; date of current version September 29, 2015.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2023-01-06T16:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>MRI</term>
					<term>Brain</term>
					<term>Oncology/tumor</term>
					<term>Image segmentation</term>
					<term>Benchmark</term>
				</keywords>
			</textClass>
			<abstract>
				<p>In this paper we report the setup and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low-and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>two years or less and require immediate treatment <ref type="bibr" target="#b34">[2]</ref>, <ref type="bibr" target="#b35">[3]</ref>. The slower growing low-grade variants, such as low-grade astrocytomas or oligodendrogliomas, come with a life expectancy of several years so aggressive treatment is often delayed as long as possible. For both groups, intensive neuroimaging protocols are used before and after treatment to evaluate the progression of the disease and the success of a chosen treatment strategy. In current clinical routine, as well as in clinical studies, the resulting images are evaluated either based on qualitative criteria only (indicating, for example, the presence of characteristic hyper-intense tissue appearance in contrast-enhanced T1-weighted MRI), or by relying on such rudimentary quantitative measures as the largest diameter visible from axial images of the lesion <ref type="bibr" target="#b36">[4]</ref>, <ref type="bibr" target="#b37">[5]</ref>.</p><p>By replacing the current basic assessments with highly accurate and reproducible measurements of the relevant tumor substructures, image processing routines that can automatically analyze brain tumor scans would be of enormous potential value for improved diagnosis, treatment planning, and follow-up of individual patients. However, developing automated brain tumor segmentation techniques is technically challenging, because lesion areas are only defined through intensity changes that are relative to surrounding normal tissue, and even manual segmentations by expert raters show significant variations when intensity gradients between adjacent structures are smooth or obscured by partial voluming or bias field artifacts. Furthermore, tumor structures vary considerably across patients in terms of size, extension, and localization, prohibiting the use of strong priors on shape and location that are important components in the segmentation of many other anatomical structures. Moreover, the so-called mass effect induced by the growing lesion may displace normal brain tissues, as do resection cavities that are present after treatment, thereby limiting the reliability of spatial prior knowledge for the healthy part of the brain. Finally, a large variety of imaging modalities can be used for mapping tumor-induced tissue changes, including T2 and FLAIR MRI (highlighting differences in tissue water relaxational properties), post-Gadolinium T1 MRI (showing pathological intratumoral take-up of contrast agents), perfusion and diffusion MRI (local water diffusion and blood flow), and 0278-0062 © 2014 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/ redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.</p><p>MRSI (relative concentrations of selected metabolites), among others. Each of these modalities provides different types of biological information, and therefore poses somewhat different information processing tasks. Because of its high clinical relevance and its challenging nature, the problem of computational brain tumor segmentation has attracted considerable attention during the past 20 years, resulting in a wealth of different algorithms for automated, semi-automated, and interactive segmentation of tumor structures (see <ref type="bibr" target="#b38">[6]</ref> and <ref type="bibr" target="#b39">[7]</ref> for good reviews). Virtually all of these methods, however, were validated on relatively small private datasets with varying metrics for performance quantification, making objective comparisons between methods highly challenging. Exacerbating this problem is the fact that different combinations of imaging modalities are often used in validation studies, and that there is no consistency in the tumor sub-compartments that are considered. As a consequence, it remains difficult to judge which image segmentation strategies may be worthwhile to pursue in clinical practice and research; what exactly the performance is of the best computer algorithms available today; and how well current automated algorithms perform in comparison with groups of human expert raters.</p><p>In order to gauge the current state-of-the-art in automated brain tumor segmentation and compare between different methods, we organized in 2012 and 2013 a Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) challenge in conjunction with the international conference on Medical Image Computing and Computer Assisted Interventions (MICCAI). For this purpose, we prepared and made available a unique dataset of MR scans of low-and high-grade glioma patients with repeat manual tumor delineations by several human experts, as well as realistically generated synthetic brain tumor datasets for which the ground truth segmentation is known. Each of 20 different tumor segmentation algorithms was optimized by their respective developers on a subset of this particular dataset, and subsequently run on the remaining images to test performance against the (hidden) manual delineations by the expert raters. In this paper we report the set-up and the results of this BRATS benchmark effort. We also describe the BRATS reference dataset and online validation tools, which we make publicly available as an ongoing benchmarking resource for future community efforts.</p><p>The paper is organized as follows. We briefly review the current state-of-the-art in automated tumor segmentation, and survey benchmark efforts in other biomedical image interpretation tasks, in Section II. We then describe the BRATS set-up and data, the manual annotation of tumor structures, and the evaluation process in Section III. Finally, we report and discuss the results of our comparisons in Sections IV and V, respectively. Section VI concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PRIOR WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms for Brain Tumor Segmentation</head><p>The number of clinical studies involving brain tumor quantification based on medical images has increased significantly over the past decades. Around a quarter of such studies relies on automated methods for tumor volumetry ( <ref type="figure">Fig. 1</ref>). Most of the <ref type="figure">Fig. 1</ref>. Results of PubMed searches for brain tumor (glioma) imaging (red), tumor quantification using image segmentation (blue), and automated tumor segmentation (green). While the tumor imaging literature has seen a nearly linear increase over the last 30 years, the number of publications involving tumor segmentation has grown more than linearly since 5-10 years. Around 25% of such publications refer to "automated" tumor segmentation.</p><p>existing algorithms for brain tumor analysis focus on the segmentation of glial tumor, as recently reviewed in <ref type="bibr" target="#b38">[6]</ref>, <ref type="bibr" target="#b39">[7]</ref>. Comparatively few methods deal with less frequent tumors such as meningioma <ref type="bibr" target="#b40">[8]</ref>- <ref type="bibr" target="#b44">[12]</ref> or specific glioma subtypes <ref type="bibr" target="#b45">[13]</ref>.</p><p>Methodologically, many state-of-the-art algorithms for tumor segmentation are based on techniques originally developed for other structures or pathologies, most notably for automated white matter lesion segmentation that has reached considerable accuracy <ref type="bibr" target="#b46">[14]</ref>. While many technologies have been tested for their applicability to brain tumor detection and segmentation-e.g., algorithms from image retrieval as an early example <ref type="bibr" target="#b41">[9]</ref>-we can categorize most current tumor segmentation methods into one of two broad families. In the so-called generative probabilistic methods, explicit models of anatomy and appearance are combined to obtain automated segmentations, which offers the advantage that domain-specific prior knowledge can easily be incorporated. Discriminative approaches, on the other hand, directly learn the relationship between image intensities and segmentation labels without any domain knowledge, concentrating instead on specific (local) image features that appear relevant for the tumor segmentation task.</p><p>Generative models make use of detailed prior information about the appearance and spatial distribution of the different tissue types. They often exhibit good generalization to unseen images, and represent the state-of-the-art for many brain tissue segmentation tasks <ref type="bibr" target="#b47">[15]</ref>- <ref type="bibr" target="#b53">[21]</ref>. Encoding prior knowledge for a lesion, however, is difficult. Tumors may be modeled as outliers relative to the expected shape <ref type="bibr" target="#b54">[22]</ref>, <ref type="bibr" target="#b55">[23]</ref> or image signal of healthy tissues <ref type="bibr" target="#b49">[17]</ref>, <ref type="bibr" target="#b56">[24]</ref> which is similar to approaches for other brain lesions, such as Multiple Sklerosis <ref type="bibr" target="#b57">[25]</ref>, <ref type="bibr" target="#b58">[26]</ref>. In <ref type="bibr" target="#b49">[17]</ref>, for instance, a criterion for detecting outliers is used to generate a tumor prior in a subsequent expectation-maximizations segmentation which treats tumor as an additional tissue class. Alternatively, the spatial prior for the tumor can be derived from the appearance of tumor-specific "bio-markers" <ref type="bibr" target="#b59">[27]</ref>, <ref type="bibr" target="#b60">[28]</ref>, or from using tumor growth models to infer the most likely localization of tumor structures for a given set of patient images <ref type="bibr" target="#b61">[29]</ref>. All these models rely on registration for accurately aligning images and spatial priors, which is often problematic in the presence of large lesions or resection cavities. In order to overcome this difficulty, both joint registration and tumor segmentation <ref type="bibr" target="#b50">[18]</ref>, <ref type="bibr" target="#b62">[30]</ref> and joint registration and estimation of tumor displacement <ref type="bibr" target="#b63">[31]</ref> have been studied. A limitation of generative models is the significant effort required for transforming an arbitrary semantic interpretation of the image, for example, the set of expected tumor substructures a radiologist would like to have mapped in the image, into appropriate probabilistic models.</p><p>Discriminative models directly learn from (manually) annotated training images the characteristic differences in the appearance of lesions and other tissues. In order to be robust against imaging artifacts and intensity and shape variations, they typically require substantial amounts of training data <ref type="bibr" target="#b64">[32]</ref>- <ref type="bibr" target="#b70">[38]</ref>. As a first step, these methods typically extract dense, voxel-wise features from anatomical maps <ref type="bibr" target="#b67">[35]</ref>, <ref type="bibr" target="#b71">[39]</ref> calculating, for example, local intensity differences <ref type="bibr" target="#b72">[40]</ref>- <ref type="bibr" target="#b74">[42]</ref>, or intensity distributions from the wider spatial context of the individual voxel <ref type="bibr" target="#b71">[39]</ref>, <ref type="bibr" target="#b75">[43]</ref>, <ref type="bibr" target="#b76">[44]</ref>. As a second step, these features are then fed into classification algorithms such as support vector machines <ref type="bibr" target="#b77">[45]</ref> or decision trees <ref type="bibr" target="#b78">[46]</ref> that learn boundaries between classes in the high-dimensional feature space, and return the desired tumor classification maps when applied to new data. One drawback of this approach is that, because of the explicit dependency on intensity features, segmentation is restricted to images acquired with the exact same imaging protocol as the one used for the training data. Even then, careful intensity calibration remains a crucial part of discriminative segmentation methods in general <ref type="bibr" target="#b79">[47]</ref>- <ref type="bibr" target="#b81">[49]</ref>, and tumor segmentation is no exception to this rule.</p><p>A possible direction that avoids the calibration issues of discriminative approaches, as well as the limitations of generative models, is the development of joint generative-discriminative methods. These techniques use a generative method in a pre-processing step to generate stable input for a subsequent discriminative model that can be trained to predict more complex class labels <ref type="bibr" target="#b82">[50]</ref>, <ref type="bibr" target="#b83">[51]</ref>.</p><p>Most generative and discriminative segmentation approaches exploit spatial regularity, often with extensions along the temporal dimension for longitudinal tasks <ref type="bibr" target="#b84">[52]</ref>- <ref type="bibr" target="#b86">[54]</ref>. Local regularity of tissue labels can be encoded via boundary modeling for both generative <ref type="bibr" target="#b49">[17]</ref>, <ref type="bibr" target="#b87">[55]</ref> and discriminative models <ref type="bibr" target="#b64">[32]</ref>, <ref type="bibr" target="#b65">[33]</ref>, <ref type="bibr" target="#b67">[35]</ref>, <ref type="bibr" target="#b87">[55]</ref>, <ref type="bibr" target="#b88">[56]</ref>, potentially enforcing non-local shape constraints <ref type="bibr" target="#b89">[57]</ref>. Markov random field (MRF) priors encourage similarity among neighboring labels in the generative context <ref type="bibr" target="#b57">[25]</ref>, <ref type="bibr" target="#b69">[37]</ref>, <ref type="bibr" target="#b70">[38]</ref>. Similarly, conditional random fields (CRFs) help enforce-or prohibit-the adjacency of specific labels and, hence, impose constraints considering the wider spatial context of voxels <ref type="bibr" target="#b68">[36]</ref>, <ref type="bibr" target="#b75">[43]</ref>. While all these segmentation models act locally, more or less at the voxel level, other approaches consider prior knowledge about the relative location of tumor structures in a more global fashion. They learn, for example, the neighborhood relationships between such structures as edema, Gadolinium-enhancing tumor structures, or necrotic parts of the tumor through hierarchical models of super-voxel clusters <ref type="bibr" target="#b74">[42]</ref>, <ref type="bibr" target="#b90">[58]</ref>, or by relating image patterns with phenomenological tumor growth models adapted to patient scans <ref type="bibr" target="#b63">[31]</ref>.</p><p>While each of the discussed algorithms was compared empirically against an expert segmentation by its authors, it is difficult to draw conclusions about the relative performance of different methods. This is because datasets and pre-processing steps differ between studies, the image modalities considered, the annotated tumor structures, and the used evaluation scores all vary widely as well <ref type="table">(Table I)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image Processing Benchmarks</head><p>Benchmarks that compare how well different learning algorithms perform in specific tasks have gained a prominent role in the machine learning community. In recent years, the idea of benchmarking has also gained popularity in the field of medical image analysis. Such benchmarks, sometimes referred to as "challenges," all share the common characteristic that different groups optimize their own methods on a training dataset provided by the organizers, and then apply them in a structured way to a common, independent test dataset. This situation is different from many published comparisons, where one group applies different techniques to a dataset of their choice, which hampers a fair assessment as this group may not be equally knowledgeable about each method and invest more effort in optimizing some algorithms than others (see <ref type="bibr" target="#b91">[59]</ref>).</p><p>Once benchmarks have been established, their test dataset often becomes a new standard in the field on how to evaluate future progress in the specific image processing task being tested. The annotation and evaluation protocols also may remain the same even when new data are added (to overcome the risk of over-fitting this one particular dataset that may take place after a while), or when related benchmarks are initiated. A key component in benchmarking is an online tool for automatically evaluating segmentations submitted by individual groups <ref type="bibr" target="#b92">[60]</ref>, as this allows the labels of the test set never to be made public. This helps ensure that any reported results are not influenced by unintentional overtraining of the method being tested, and that they are therefore truly representative of the method's segmentation performance in practice.</p><p>Recent examples of community benchmarks dealing with medical image segmentation and annotation include algorithms for artery centerline extraction <ref type="bibr" target="#b93">[61]</ref>, <ref type="bibr" target="#b94">[62]</ref>, vessel segmentation and stenosis grading <ref type="bibr" target="#b95">[63]</ref>, liver segmentation <ref type="bibr" target="#b96">[64]</ref>, <ref type="bibr" target="#b97">[65]</ref>, detection of microaneurysms in digital color fundus photographs <ref type="bibr" target="#b98">[66]</ref>, and extraction of airways from CT scans <ref type="bibr" target="#b99">[67]</ref>. Rather few community-wide efforts have focused on segmentation algorithms applied to images of the brain (a current example deals with brain extraction ("masking") <ref type="bibr" target="#b100">[68]</ref>), although many of the validation frameworks that are used to compare different segmenters and segmentation algorithms, such as STAPLE <ref type="bibr" target="#b101">[69]</ref>, <ref type="bibr" target="#b102">[70]</ref>, have been developed for applications in brain imaging, or even brain tumor segmentation <ref type="bibr" target="#b103">[71]</ref>.  <ref type="table">I  DATA SETS, MR IMAGE MODALITIES, EVALUATION SCORES, AND EVEN TUMOR TYPES USED FOR SELF-REPORTED PERFORMANCES IN THE BRAIN  TUMOR IMAGE SEGMENTATION LITERATURE DIFFER WIDELY. SHOWN IS A SELECTION OF ALGORITHMS DISCUSSED HERE AND IN [7]. TUMOR  TYPE IS DEFINED AS G-GLIOMA (UNSPECIFIED), HG-HIGH-GRADE GLIOMA, LG-LOW-GRADE GLIOMA, M-MENINGIOMA; "NA" INDICATES  THAT NO INFORMATION IS REPORTED. WHEN AVAILABLE THE NUMBER OF TRAINING AND TESTING DATASETS IS REPORTED, ALONG WITH THE  TESTING MECHANISM: TT-SEPARATE TRAINING AND TESTING DATASETS, CV-CROSS-VALIDATION</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SET-UP OF THE BRATS BENCHMARK</head><p>The BRATS benchmark was organized as two satellite challenge workshops in conjunction with the MICCAI 2012 and 2013 conferences. Here we describe the set-up of both challenges with the participating teams, the imaging data and the manual annotation process, as well as the validation procedures and online tools for comparing the different algorithms. The BRATS online tools continue to accept new submissions, allowing new groups to download the training and test data and submit their segmentations for automatic ranking with respect to all previous submissions. <ref type="bibr" target="#b33">1</ref> A common entry page to both benchmarks, as well as to the latest BRATS-related initiatives is www.braintumorsegmentation.org. <ref type="bibr" target="#b34">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The MICCAI 2012 and 2013 Benchmark Challenges</head><p>The first benchmark was organized on October 1, 2012 in Nice, France, in a workshop held as part of the MICCAI 2012 conference. During Spring 2012, participants were solicited through private e-mails as well as public e-mail lists and the MICCAI workshop announcements. Participants had to register with one of the online systems (cf. Section III-F) and could download annotated training data. They were asked to submit a four page summary of their algorithm, also reporting a cross-validated training error. Submissions were reviewed by the organizers and a final group of twelve participants were invited to contribute to the challenge. The training data the participants obtained in order to tune their algorithms consisted of multi-contrast MR scans of 10 low-and 20 high-grade glioma patients that had been manually annotated with two tumor labels ("edema" and "core," cf. Section III-D) by a trained human expert. The training data also contained simulated images for 25 high-grade and 25 low-grade glioma subjects with the same two "ground truth" labels. In a subsequent "on-site challenge" at the MICCAI workshop, the teams were given a 12 h time period to evaluate previously unseen test images. The test images consisted of 11 high-and 4 low-grade real cases, as well as 10 high-and 5 low-grade simulated images. The resulting segmentations were then uploaded by each team to the online tools, which automatically computed performance scores for the two tumor structures. Of the twelve groups that participated in the benchmark, six submitted their results in time during the on-site challenge, and one group submitted their results shortly afterwards <ref type="bibr">(Subbanna)</ref>. During the plenary discussions it became apparent that using only two basic tumor classes was insufficient as the "core" label contained substructures with very different appearances in the different modalities. We therefore had all the training data re-annotated with four tumor labels, refining the initially rather broad "core" class by labels for necrotic, cystic and enhancing substructures. We asked all twelve workshop participants to update their algorithms to consider these new labels and to submit their segmentation  <ref type="table">II  OVERVIEW OF THE ALGORITHMS EMPLOYED IN 2012 AND 2013. FOR A FULL DESCRIPTION PLEASE REFER TO THE APPENDIX AND THE WORKSHOP  PROCEEDINGS AVAILABLE ONLINE (SEE SECTION III-A). THREE NON-AUTOMATIC ALGORITHMS REQUIRED A MANUAL INITIALIZATION</ref> results-on the same test data-to our evaluation platform in an "off-site" evaluation about six months after the event in Nice, and ten of them submitted updated results <ref type="table">(Table II)</ref>.</p><p>The second benchmark was organized on September 22, 2013 in Nagoya, Japan in conjunction with MICCAI 2013. Participants had to register with the online systems and were asked to describe their algorithm and report training scores during the summer, resulting in ten teams submitting short papers, all of which were invited to participate. The training data for the benchmark was identical to the real training data of the 2012 benchmark. No synthetic cases were evaluated in 2013, and therefore no synthetic training data was provided. The participating groups were asked to also submit results for the 2012 test dataset (with the updated labels) as well as to 10 new test datasets to the online system about four weeks before the event in Nagoya as part of an "off-site" leaderboard evaluation. The "on-site challenge" at the MICCAI 2013 workshop proceeded in a similar fashion to the 2012 edition: the participating teams were provided with 10 high-grade cases, which were previously unseen test images not included in the 2012 challenge, and were given a 12 h time period to upload their results for evaluation. Out of the ten groups participating in 2013 <ref type="table">(Table II)</ref>, seven groups submitted their results during the on-site challenge; the remaining three submitted their results shortly afterwards <ref type="bibr">(Buendia, Guo, Taylor)</ref>.</p><p>Altogether, we report three different test results from the two events: one summarizing the on-site 2012 evaluation with two tumor labels for a test set with 15 real cases (11 high-grade, four low-grade) and 15 synthetically generated images (10 highgrade, five low-grade); one summarizing the on-site 2013 evaluation with four tumor labels on a fresh set of 10 new real cases (all high-grade); and one from the off-site tests which ranks all 20 participating groups from both years, based on the 2012 real test data with the updated four labels. Our emphasis is on the last of the three tests. <ref type="table">Table II</ref> contains an overview of the methods used by the participating groups in both challenges. In 2012, four out of the twelve participants used generative models, one was a generative-discriminative approach, and five were discriminative; seven used some spatially regularizing model component. Two methods required manual initialization. The two automated segmentation methods that topped the list of competitors during the on-site challenge of the first benchmark used a discriminative probabilistic approach relying on a random forest classifier, boosting the popularity of this approach in the second year. As a result, in 2013 participants employed one generative model, one discriminative-generative model, and eight discriminative models out of which a total of four used random forests as the central learning algorithm; seven had a processing step that enforced spatial regularization. One method required manual initialization. A detailed description of each method is available in the workshop proceedings, <ref type="bibr" target="#b35">3</ref> as well as in the Appendix/Online Supporting Information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Tumor Segmentation Algorithms Tested</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Image Datasets</head><p>Clinical Image Data: The clinical image data consists of 65 multi-contrast MR scans from glioma patients, out of which 14 have been acquired from low-grade (histological diagnosis: astrocytomas or oligoastrocytomas) and 51 from high-grade (anaplastic astrocytomas and glioblastoma multiforme tumors) glioma patients. The images represent a mix of pre-and post-therapy brain scans, with two volumes showing resections. They were acquired at four different centers-Bern University, Debrecen University, Heidelberg University, and Massachusetts General Hospital-over the course of several years, using MR scanners from different vendors and with different field strengths (1.5T and 3T) and implementations of the imaging sequences (e.g., 2D or 3D). The image datasets used in the study all share the following four MRI contrasts <ref type="figure" target="#fig_0">(Fig. 2)</ref>. 1) T1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1-6 mm slice thickness. 2) T1c: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients. 3) T2: T2-weighted image, axial 2D acquisition, with 2-6 mm slice thickness. 4) FLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2-6 mm slice thickness. To homogenize these data we co-registered each subject's image volumes rigidly to the T1c MRI, which had the highest spatial resolution in most cases, and resampled all images to 1 mm isotropic resolution in a standardized axial orientation with a linear interpolator. We used a rigid registration model with the mutual information similarity metric as it is implemented in ITK <ref type="bibr" target="#b106">[74]</ref> ("VersorRigid3DTransform" with "MattesMutualInformation" similarity metric and three multi-resolution levels). No attempt was made to put the individual patients in a common reference space. All images were skull stripped <ref type="bibr" target="#b107">[75]</ref> to guarantee anomymization of the patients.</p><p>Synthetic Image Data: The synthetic data of the BRATS 2012 challenge consisted of simulated images for 35 high-grade and low-grade gliomas that exhibit comparable tissue contrast properties and segmentation challenges as the clinical dataset <ref type="figure" target="#fig_0">(Fig. 2, last row)</ref>. The same image modalities as for the real data were simulated, with similar 1 mm resolution. The images were generated using the TumorSim software, a cross-platform simulation tool that combines physical and statistical models to generate synthetic ground truth and synthesized MR images with tumor and edema <ref type="bibr" target="#b108">[76]</ref>. It models infiltrating edema adjacent to tumors, local distortion of healthy tissue, and central contrast enhancement using the tumor growth model of Clatz et al. <ref type="bibr" target="#b109">[77]</ref>, combined with a routine for synthesizing texture similar to that of real MR images. We parameterized the algorithm according to the parameters proposed in <ref type="bibr" target="#b108">[76]</ref>, and applied it to anatomical maps of healthy subjects from the BrainWeb simulator <ref type="bibr" target="#b110">[78]</ref>, <ref type="bibr" target="#b111">[79]</ref>. We synthesized image volumes and degraded them with different noise levels and intensity inhomogeneities, using Gaussian noise and polynomial bias fields with random coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Expert Annotation of Tumor Structures</head><p>While the simulated images came with "ground truth" information about the localization of the different tumor structures, the clinical images required manual annotations. We defined four types of intra-tumoral structures, namely "edema," "non-enhancing (solid) core," "necrotic (or fluid-filled) core," and "non-enhancing core." These tumor substructures meet specific radiological criteria and serve as identifiers for similarly-looking regions to be recognized through algorithms processing image information rather than offering a biological interpretation of the annotated image patterns. For example, "non-enhancing core" labels may also comprise normal enhancing vessel structures that are close to the tumor core, and "edema" may result from cytotoxic or vasogenic processes of the tumor, or from previous therapeutical interventions.</p><p>Tumor Structures and Annotation Protocol: We used the following protocol for annotating the different visual structures, where present, for both low-and high-grade cases (illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref>).</p><p>1) The "edema" was segmented primarily from T2 images. FLAIR was used to cross-check the extension of the edema and discriminate it against ventricles and other fluid-filled structures. The initial "edema" segmentation in T2 and FLAIR contained the core structures that were then relabeled in subsequent steps [ <ref type="figure" target="#fig_1">Fig. 3(A)</ref>]. 2) As an aid to the segmentation of the other three tumor substructures, the so-called gross tumor core-including both enhancing and non-enhancing structures-was first segmented by evaluating hyper-intensities in T1c (for highgrade cases) together with the inhomogenous component of the hyper-intense lesion visible in T1 and the hypo-intense regions visible in T1 [ <ref type="figure" target="#fig_1">Fig. 3(B)</ref>]. 3) The "enhancing core" of the tumor was subsequently segmented by thresholding T1c intensities within the resulting gross tumor core, including the Gadolinium enhancing tumor rim and excluding the necrotic center and vessels. 5) Finally, the "non-enhancing (solid) core" structures were defined as the remaining part of the gross tumor core, i.e., after subtraction of the "enhancing core" and the "necrotic (or fluid-filled) core" structures [ <ref type="figure" target="#fig_1">Fig. 3(D)</ref>]. Following this protocol, the MRI scans were annotated by a trained team of radiologists and altogether seven radiographers in Bern, Debrecen and Boston. They outlined structures in every third axial slice, interpolated the segmentation using morphological operators (region growing), and visually inspected the results in order to perform further manual corrections, if necessary. All segmentations were performed using the 3D slicer software <ref type="bibr" target="#b37">5</ref> , taking about 60 min per subject. As mentioned previously, the tumor labels used initially in the BRATS challenge contained only two classes for both high-and low-grade glioma cases: "edema," which was defined similarly as the edema class above, and "core" representing the three core classes. The simulated data used in the 2012 challenge also had ground truth labels only for "edema" and "core."</p><p>Consensus Labels: In order to deal with ambiguities in individual tumor structure definitions, especially in infiltrative tumors for which clear boundaries are hard to define, we had all subjects annotated by several experts, and subsequently fused the results to obtain a single consensus segmentation for each subject. The 30 training cases were labeled by four different raters, and the test set from 2012 was annotated by three. The additional testing cases from 2013 were annotated by one rater. For the data sets with multiple annotations we fused the resulting label maps by assuming increasing "severity" of the disease from edema to non-enhancing (solid) core to necrotic (or fluid-filled) core to enhancing core, using a hierarchical majority voting scheme that assigns a voxel to the highest class to which at least half of the raters agree on (Algorithm 1). To illustrate this rule: a voxel that has been labeled as edema, edema, non-enhancing core, and necrotic core by the four annotators would be assigned to non-enhancing core structure as this is the most serious label that 50% of the experts agree on.</p><p>We chose this hierarchical majority vote to include prior knowledge about the structure and the ranking of the labels. A direct application of other multi-class fusion schemes that do not consider relations between the class labels, such as the STAPLE algorithm <ref type="bibr" target="#b101">[69]</ref>, lead to implausible fusion results where, for example, edema and normal voxels formed regions that were surrounded by "core" structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Evaluation Metrics and Ranking</head><p>Tumor Regions Used for Validation: The tumor structures represent the visual information of the images, and we provided the participants with the corresponding multi-class labels to train their algorithms. For evaluating the performance of the segmentation algorithms, however, we grouped the different structures into three mutually inclusive tumor regions that better represent the clinical application tasks, for example, in tumor volumetry. We obtain 1) the "whole" tumor region (including all four tumor structures), 2) the tumor "core" region (including all tumor structures except "edema"), 3) and the "active" tumor region (only containing the "enhancing core" structures that are unique to high-grade cases). is the area that is predicted to be lesion by-for example-an algorithm (outlined red), and is predicted to be normal. has some overlap with in the right lateral part of the lesion, corresponding to the area referred to as in the definition of the Dice score (Eq. III.E).</p><p>Examples of all three regions are shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. By evaluating multiple binary segmentation tasks, we also avoid the problem of specifying misclassification costs for trading false assignments in between, for example, edema and necrotic core structures or enhancing core and normal tissue, which cannot easily be solved in a global manner. Performance Scores: For each of the three tumor regions we obtained a binary map with algorithmic predictions and the experts' consensus truth , and we calculated the well-known Dice score where is the logical AND operator, is the size of the set (i.e., the number of voxels belonging to it), and and represent the set of voxels where and , respectively <ref type="figure" target="#fig_2">(Fig. 4</ref>). The Dice score normalizes the number of true positives to the average size of the two segmented areas. It is identical to the F score (the harmonic mean of the precision recall curve) and can be transformed monotonously to the Jaccard score.</p><p>We also calculated the so-called sensitivity (true positive rate) and specificity (true negative rate)</p><p>where and represent voxels where and , respectively.</p><p>Dice score, sensitivity, and specificity are measures of voxel-wise overlap of the segmented regions. A different class of scores evaluates the distance between segmentation boundaries, i.e., the surface distance. A prominent example is the Hausdorff distance calculating for all points on the surface of a given volume the shortest least-squares distance to points on the surface of the other given volume , and vice versa, finally returning the maximum value over all Returning the maximum over all surface distances, however, makes the Hausdorff measure very susceptible to small outlying subregions in either or . In our evaluation of the "active tumor" region, for example, both or may consist of multiple small areas or nonconvex structures with high surface-to-area ratio. In the evaluation of the "whole tumor," predictions with few false positive regions-that do not substantially affect the overall quality of the segmentation as they could be removed with an appropriate postprocessing-might also have a drastic impact on the overall Hausdorff score. To this end we used a robust version of the Hausdorff measure-reporting not the maximal surface distance between and , but the 95% quantile of it.</p><p>Significance Tests: In order to compare the performance of different methods across a set of images, we performed two types of significance tests on the distribution of their Dice scores. For the first test we identified the algorithm that performed best in terms of average Dice score for a given task, i.e., for the whole tumor region, tumor core region, or active tumor region. We then compared the distribution of the Dice scores of this "best" algorithm with the corresponding distributions of all other algorithms. In particular, we used a nonparametric Cox-Wilcoxon test, testing for significant differences at a 5% significance level, and recorded which of the alternative methods could not be distinguished from the "best" method this way.</p><p>In the same way we also compared the distribution of the inter-rater Dice scores, obtained by pooling the Dice scores across each pair of human raters and across subjects-with each subject contributing six scores if there are four raters, and three scores if there are three raters-to the distribution of the Dice scores calculated for each algorithm in a comparison with the consensus segmentation. We then recorded whenever the distribution of an algorithm could not be distinguished from the inter-rater distribution this way. We note that our inter-rater score somewhat overestimates variability as it is calculated from two manual annotations that may both be very eccentric. In the same way a comparison between a rater and the consensus label may somewhat underestimates variability, as the same manual annotations had contributed to the consensus label it now is compared against.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Online Evaluation Platforms</head><p>A central element of the BRATS benchmark is its online evaluation tool. We used two different platforms: the Virtual Skeleton Database (VSD), hosted at the University of Bern, and the Multimedia Digital Archiving System (MIDAS), hosted at Kitware <ref type="bibr" target="#b112">[80]</ref>. On both systems participants can download annotated training and "blinded" test data, and upload their segmentations for the test cases. Each system automatically evaluates the performance of the uploaded label maps, and makes detailed-case by case-results available to the participant. Average scores for the different subgroups are also reported online, as well as a ranked comparison with previous results submitted for the same test sets. . Dice scores of inter-rater variation (top left), and variation around the "fused" consensus label (top right). Shown are results for the "whole" tumor region (including all four tumor structures), the tumor "core" region (including enhancing, non-enhancing core, and necrotic structures), and the "active" tumor region (that features the T1c enhancing structures). Black boxplots show training data (30 cases); gray boxes show results for the test data (15 cases). Scores for "active" tumor region are calculated for high-grade cases only (15/11 cases). Boxes report quartiles including the median; whiskers and dots indicate outliers (some of which are below 0.5 Dice); and triangles report mean values. Table at the bottom shows quantitative values for the training and test datasets, including scores for low-and high-grade cases (LG/HG) separately; here "std" denotes standard deviation, and "mad" denotes median absolute deviance.</p><p>The VSD <ref type="bibr" target="#b38">6</ref> provides an online repository system tailored to the needs of the medical research community. In addition to storing and exchanging medical image datasets, the VSD provides generic tools to process the most common image format types, includes a statistical shape modeling framework and an ontology-based searching capability. The hosted data is accessible to the community and collaborative research efforts. In addition, the VSD can be used to evaluate the submissions of competitors during and after a segmentation challenge. The BRATS data is publicly available at the VSD, allowing any team around the world to develop and test novel brain tumor segmentation algorithms. Ground truth segmentation files for the BRATS test data are hosted on the VSD but their download is protected through appropriate file permissions. The users upload their segmentation results through a web-interface, review the uploaded segmentation and then choose to start an automatic evaluation process. The VSD automatically identifies the ground truth corresponding to the uploaded segmentations. The evaluation of the different label overlap measures used to evaluate the quality of the segmentation (such as Dice scores) runs in the background and takes less than one minute per segmentation. Individual and overall results of the evaluation are automatically published on the VSD webpage and can be downloaded as a CSV file for further statistical analysis. Currently, the VSD has evaluated more than segmentations and recorded over 100 registered BRATS users. We used it to host both the training and test data, and to perform the evaluations of the on-site challenges. Up-to- <ref type="bibr" target="#b38">6</ref> www.virtualskeleton.ch date ranking is available at the VSD for researchers to continuously monitor new developments and streamline improvements.</p><p>MIDAS <ref type="bibr" target="#b39">7</ref> is an open source toolkit that is designed to manage grand challenges. The toolkit contains a collection of server, client, and stand-alone tools for data archiving, analysis, and access. This system was used in parallel with VSD for hosting the BRATS training and test data in 2012, as well as managing submissions from participants and providing final scores using a collection of metrics. It has not been used any more for the 2013 BRATS challenge.</p><p>The software that generates the comparison metrics between ground truth and user submissions in both VSD and MIDAS is available as the open source COVALIC (Comparison and Validation of Image Computing) toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. RESULTS</head><p>In a first step we evaluate the variability between the segmentations of our experts in order to quantify the difficulty of the different segmentation tasks. Results of this evaluation also serve as a baseline we can use to compare our algorithms against in a second step. As combining several segmentations may potentially lead to consensus labels that are of higher quality than the individual segmentations, we perform an experiment that applies the hierarchical fusion algorithm to the automatic segmentations as a final step. LG cases for the real images and 10/5 HG/LG cases for the synthetic scans. All datasets from the 2012 on-site challenge featured "whole" and "core" region labels only. On-site test set for 2013 consisted of 10 real HG cases with four-class annotations, of which "whole," "core," "active" regions were evaluated (see text). Best results for each task are underlined. Top performing algorithms of the on-site challenge were Hamamci, Zikic, and Bauer in 2012; and Tustison, Meier, and Reza in 2013. <ref type="figure" target="#fig_3">Fig. 5</ref> analyzes the inter-rater variability in the four-label manual segmentations of the training scans (30 cases, four different raters), as well as of the final off-site test scans (15 cases, three raters). The results for the training and test datasets are overall very similar, although the inter-rater variability is a bit higher (lower Dice scores) in the test set, indicating that images in our training dataset were slightly easier to segment <ref type="figure" target="#fig_3">(Fig. 5</ref>, plots at the top). The scores obtained by comparing individual raters against the consensus segmentation provides an estimate of an upper limit for the performance of any algorithmic segmentation, indicating that segmenting the whole tumor region for both low-and high-grade and the tumor core region for high-grade is comparatively easy, while identifying the "core" in low-grade glioma and delineating the enhancing structures for high-grade cases is considerably more difficult <ref type="figure" target="#fig_3">(Fig. 5</ref>, table at the bottom). The comparison between an individual rater and the consensus segmentation, however, may be somewhat overly optimistic with respect to the upper limit of accuracy that can be obtained on the given datasets, as the consensus label is generated using the rater's segmentation it is compared against. So we use the inter-rater variation as an unbiased proxy that we compare with the algorithmic segmentations in the remainder. This sets the bar that has to be passed by an algorithm to Dice scores in the high 80% for the whole tumor region (median 87%), to scores in the high 80% for "core" region (median 94% for high-grade, median 82% for low-grade), and to average scores in the high 70% for "active" tumor region (median 77%) ( <ref type="figure" target="#fig_3">Fig. 5</ref>, table at the bottom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Inter-Rater Variability of Manual Segmentations</head><p>We note that on all datasets and in all three segmentation tasks the dispersion of the Dice score distributions is quite high, with standard deviations of 10% and more in particular for the most difficult tasks (tumor core in low-grade patients, active core in high-grade patients), underlining the relevance of comparing the distributions rather than comparing summary statistics such as the mean or the median and, for example, ranking measures thereof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance of Individual Algorithms</head><p>On-Site Evaluation: Results from the on-site evaluations are reported in <ref type="figure" target="#fig_4">Fig. 6</ref>. Synthetic images were only evaluated in the 2012 challenge, and the winning algorithms on these images were developed by Bauer, Zikic, and Hamamci <ref type="figure" target="#fig_4">(Fig. 6</ref>, top right). The same methods also ranked top on the real data in the same year ( <ref type="figure" target="#fig_4">Fig. 6</ref>, top left), performing particularly well for whole tumor and core segmentation. Here, Hamamci required some user interaction for an optimal initialization, while the methods by Bauer and Zikic were fully automatic. In the on-site challenge, the winning algorithms were those by Tustison, Meier, and Reza, with Tustison performing best in all three segmentation tasks <ref type="figure" target="#fig_4">(Fig. 6, bottom left)</ref>.</p><p>Overall, the performance scores from the on-site test in were higher than those in the previous off-site leaderboard evaluation (compare <ref type="figure">Fig. 7</ref>, top with <ref type="figure" target="#fig_4">Fig. 6</ref>, bottom left). As the off-site test data contained the test cases from the previous year, one may argue that the images chosen for the 2013 on-site evaluation were somewhat easier to segment than the on-site test images in the previous-and one should <ref type="figure">Fig. 7</ref>. Average Dice scores from the "off-site" test, for all algorithms submitted during BRATS 2012 and 2013. The table at the top reports average Dice scores for "whole" lesion, tumor "core" region, and "active" core region, both for the low-grade (LG) and high-grade (HG) subsets combined and considered separately. Algorithms with the best average Dice score for the given task are underlined; those indicated in bold have a Dice score distribution on the test cases that is similar to the best (see also <ref type="figure" target="#fig_5">Fig. 8</ref>). "Best Combination" is the upper limit of the individual algorithmic segmentations (see text), "Fused_4" reports exemplary results when pooling results from Subbanna, Zhao (I), Menze (D), and Hamamci (see text). Reported average computation times per case are in minutes; an indication regarding CPU or Cluster based implementation is also provided. Plots at the bottom show the sensitivities and specificities of the corresponding algorithms. Colors encode the corresponding values of the different algorithms; written names have only approximate locations. be cautious about a direct comparison of on-site results from the two challenges.</p><p>Off-Site Evaluation: Results on the off-site evaluation (Figs. 7 and 8) allow us to compare algorithms from both challenges, and also to consider results from algorithms that did not converge within the given time limit of the on-site evaluation (e.g., Menze, Geremia, Riklin Raviv). We performed significance tests on the Dice score to identify which algorithms performed best or similar to the best one for each segmentation task <ref type="figure">(Fig. 7)</ref>. We also performed significance tests on the Dice scores to identify which algorithms had a performance that is similar to the inter-rater variation that are indicated by stars on top of the box plots in <ref type="figure" target="#fig_5">Fig. 8</ref>. For "whole" tumor segmentation, Zhao (I) was the best method, followed by Menze (D), which performed the best on low-grade cases; Zhao (I), Menze (D), Tustison, and Doyle report results with Dice scores that were similar to the inter-rater variation. For tumor "core" segmentation, Subbanna performed best, followed by Zhao (I) that  <ref type="figure">Fig. 7</ref>), which were used here to rank the methods. Also shown are results from four "Fused" algorithmic segmentations (see text for details), and the performance of the "Best Combination" as the upper limit of individual algorithmic performance. Methods with a star on top of the boxplot have Dice scores as high or higher than those from inter-rater variation. Hausdorff distances are reported on a logarithmic scale.</p><p>was best on low-grade cases; only Subbanna has Dice scores similar to the inter-rater scores. For "active" core segmentation Festa performs best; with the spread of the Dice scores being rather high for the "active" tumor segmentation task, we find a high number of algorithms (Festa, Hamamci, Subbanna, Riklin Raviv, Menze (D), Tustison) to have Dice scores that do not differ significantly from those recorded for the inter-rater variation. Sensitivity and specificity varied considerably between methods <ref type="figure">(Fig. 7, bottom)</ref>.</p><p>Using the Hausdorff distance metric we observe a ranking that is overall very similar ( <ref type="figure">Fig. 7</ref>, boxes on the right), suggesting that the Dice scores indicate the general algorithmic performances sufficiently well. Inspecting segmentations of the one method that is an exception to this rule (Festa), we find it to segment the active region of the tumor very well for most volumes, but also to miss all voxels in the active region of three volumes (apparently removed from a very strong spatial regularization), with low Dice scores and Hausdorff distances of more than 50 mm. Averaged over all patients, this still leads to a very good Dice score, but the mean Hausdorff distance is unfavourably dominated by the three segmentations that failed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Performance of Fused Algorithms</head><p>An Upper Limit of Algorithmic Performance: One can fuse algorithmic segmentations by identifying-for each test scan and each of the three segmentation tasks-the best segmentation generated by any of the given algorithms. This set of "optimal" segmentations (referred to as "Best Combination" in the remainder) has an average Dice score of about 90% for the "whole" tumor region, about 80% for the tumor "core" region, and about 70% for the "active" tumor region ( <ref type="figure">Fig. 7, top)</ref>, surpassing the scores obtained for inter-rater variation <ref type="figure" target="#fig_5">(Fig. 8</ref>). However, since fusing segmentations this way cannot be performed without actually knowing the ground truth, these values can only serve as a theoretical upper limit for the tumor segmentation algorithms being evaluated. The average Dice score of the algorithm performing best on the given task are about 10% below these numbers.</p><p>Hierarchical Majority Vote: In order to obtain a mechanism for fusing algorithmic segmentations in more practical settings, we first ranked the available algorithms according to their average Dice score across all cases and all three segmentation tasks, and then selected the best half. While this procedure guaranteed that we used meaningful segmentations for the subsequent pooling, we note that the resulting set included algorithms that performed well in one or two tasks, but performed clearly below average in the third one. Once the 10 best algorithms were identified this way, we sampled random subsets of 4, 6, and 8 of those algorithms, and fused them using the same hierarchical majority voting scheme as for combining expert annotations (Section III-D). We repeated this sampling and pooling procedure ten times. The results are shown in <ref type="figure" target="#fig_5">Fig. 8</ref> (labeled "Fused_4," "Fused_6," and "Fused_8"), together with the pooled results for the full set of the 10 segmentations (named "Fused_10"). Exemplary segmentations for a Fused_4 sample are shown in <ref type="figure" target="#fig_6">Fig. 9</ref>-in this case, pooling the results from Subbanna, Zhao (I), Menze (D), and Hamamci. The corresponding Dice scores are reported in the table in <ref type="figure">Fig. 7</ref>.</p><p>We found that results obtained by pooling four or more algorithms always outperformed those of the best individual algorithm for the given segmentation task. The hierarchical majority voting reduces the number of segmentations with poor Dice scores, leading to very robust predictions. It provides segmentations that are comparable to or better than the inter-rater Dice score, and it reaches the hypothetical limit of the "Best Combination" of case-wise algorithmic segmentations for all three tasks <ref type="figure" target="#fig_5">(Fig. 8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overall Segmentation Performance</head><p>The synthetic data was segmented very well by most algorithms, reaching Dice scores on the synthetic data that were much higher than those for similar real cases <ref type="figure" target="#fig_4">(Fig. 6, top left)</ref>, even surpassing the inter-rater accuracies. As the synthetic datasets have a high variability in tumor shape and location, but are less variable in intensity and less artifact-loaded than the real images, these results suggest that the algorithms used are capable of dealing well with variability in shape and location of the tumor segments, provided intensities can be calibrated in a reproducible fashion. As intensity-calibration of magnetic resonance images remains a challenging problem, a more explicit use of tumor shape information may still help to improve the performance, for example from simulated tumor shapes <ref type="bibr" target="#b113">[81]</ref> or simulations that are adapted to the geometry of the given patients <ref type="bibr" target="#b63">[31]</ref>.</p><p>On the real data some of the automated methods reached performances similar to the inter-rater variation. The rather low scores for inter-rater variability (Dice scores in the range 74%-85%) indicate that the segmentation problem was difficult even for expert human raters. In general, most algorithms were capable of segmenting the "whole" region tumor quite well, with some algorithms reaching Dice scores of 80% and more (Zhao (I) has 82%). Segmenting the tumor "core" region worked surprisingly well for high-grade gliomas, and reasonably well for low-grade cases-considering the absence of enhancements in T1c that guide segmentations for high-grade tumors-with Dice scores in the high 60% (Subbanna has 70%). Segmenting small isolated areas of the "active" region in high-grade gliomas was the most difficult task, with the top algorithms reaching Dice scores in the high 50% (Festa has 61%). Hausdorff distances of the best algorithms are around 5-10 mm for the "whole" and the "active" tumor region, and about 20 mm for the tumor "core" region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The Best Algorithm and Caveats</head><p>This benchmark cannot answer the question of what algorithm is overall "best" for glioma segmentation. We found that no single algorithm among the ones tested ranked in the top five for all three subtasks, although Hamamci, Subbanna, Menze (D), and Zhao (I) did so for two tasks ( <ref type="figure" target="#fig_5">Fig. 8;</ref> considering Dice score). The results by Guo, Menze (D), Subbanna, Tustison, and Zhao (I) were comparable in all three tasks to those of the best method for respective task (indicated in bold in <ref type="figure">Fig. 7</ref>). Menze (D), Zhao (I), and Riklin Raviv led the ranking of the Hausdorff scores for two of the subtasks, and followed Hamamci and Subbanna for the third one.</p><p>Among the BRATS 2012 methods, we note that only Hamamci and Geremia performed comparably in the "off-site" and the "on-site" challenges, while the other algorithms performed significantly better in the "off-site" test than in the previous "on-site" evaluation. Several factors may have led to this discrepancy. Some of the groups had difficulties in submitting viable results during the "on-site" challenge and resolved them only for the "off-site" evaluation (Menze, Riklin Raviv). Others used algorithms during the "off-site" challenge that were significantly updated and reworked after the 2012 event <ref type="bibr">(Subbanna, Shin)</ref>. All 2012 participants had to adapt their algorithms to the new four-class labels and, if discriminative learning methods were used, to retrain their algorithms which also may have contributed to fluctuations in performance. Finally, we cannot rule out that some cross-checking between results of updated algorithms and available test images may have taken place in between the 2012 workshop and the 2013 "off-site" test.</p><p>There is another limitation regarding the direct comparison of "off-site" results between the 2012 and the 2013 workshop participants, as the test setting was inadvertently stricter for the latter group. In particular, the 2012 participants had several months to work with the test images and improve scores before the "off-site" evaluation took place-which, they were informed, would be used in a final ranking. In contrast, the 2013 groups were permitted access to those data only four weeks be-fore their competition and were not aware that these images would be used for a broad comparison. It is therefore worth pointing out, once again, the algorithms that performed best on the on-site tests: these were the methods by Bauer, Zikic, and Hamamci in 2012, and Tustison's method in 2013.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. "Winning" Algorithmic Properties</head><p>A majority of the top ranking algorithms relied on a discriminative learning approach, where low-level image features were generated in a first step, and a discriminative classifier was applied in a second step, transforming local features into class probabilities with MRF regularization to produce the final set of segmentations. Both Zikic and Menze (D) used the output of a generative model as input to a discriminative classifier in order to increase the robustness of intensity features. However, also other approaches that only used image intensities and standard normalization algorithms such as N4ITK <ref type="bibr" target="#b114">[82]</ref> did surprisingly well. The spatial processing by Zhao (I), which considers information about tumor structure at a regional "super-voxel" level, did exceptionally well for "whole" tumor and tumor "core." One may expect that performing such a non-local spatial regularization might also improve results of other methods. Most algorithms ranking in the lower half of the list used rather basic image features and did not employ a spatial regularization strategy, featuring small false positive outliers that decreased Dice score and increased the average Hausdorff distance.</p><p>Given the excellent results by the semi-automatic methods from Hamamci and Guo (and those by Riklin Raviv for the active tumor region), and because tumor segmentations will typically be looked at in the context of a clinical workflow anyway, it may be beneficial to take advantage of some user interaction, either in an initialization or in a postprocessing phase. In light of the clear benefit of fusing multiple automatic segmentations, demonstrated in Section IV-C, user interaction may also prove helpful in selecting the best segmentation maps for subsequent fusion.</p><p>The required computation time varied significantly among the participating algorithms, ranging from a few minutes to several hours. We observed that most of the computational burden related to feature detection and image registration sub-tasks. In addition, it was observed that a good understanding of the image resolution and amount of image subsampling can lead to a good trade-off between speed improvements and segmentation quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Fusing Automatic Segmentations</head><p>We note that fusing segmentations from different algorithms always performed better than the best individual algorithm applied to the same task. This observation aligns well with a common concept from ensemble learning, when a set of predictors that are unbiased but with high variability in the individual prediction, improve when their predictions are pooled <ref type="bibr" target="#b115">[83]</ref>. In that case, averaging over multiple predictors reduces variance and, hence, reduces the prediction error. Subselecting only the best few segmentations, i.e., those with the least bias (or average misclassification) further improves results. In general there are two extrema: variance is maximal for single observations and minimal after fusing many, while bias is minimal for the one top-ranking algorithm and maximal when including a large number of (also lesser) predictions. For many applications, an optimum is reached in between these two extrema, depending on the bias and variance of the predictors that are fused. Optimizing the ensemble prediction by balancing variability reduction (fuse many predictors) and bias removal (fuse a few selected only) can be done on a test set representing the overall population, or for the individual image volume when partial annotation is available-for example from the limited user interaction mentioned above. Statistical methods that estimate and weight the performance of individual contributions-for example, based on appropriate multi-class extensions of STAPLE <ref type="bibr" target="#b101">[69]</ref> and related probabilistic models <ref type="bibr" target="#b51">[19]</ref>, <ref type="bibr" target="#b116">[84]</ref>-may also be used to trade bias and variance in an optimal fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Limitations of the BRATS Benchmark</head><p>When designing the BRATS study, we made several choices that may have impacted the results and that could potentially have been improved. For example, we decided to homogenize the data by co-registering and reformatting each subject's image volumes using rigid registration and linear interpolation, as described in Section III-C. Although the registration itself was found to work well (as it was always between images acquired from the same subject and in the same acquisition session), it may have been advisable to use a more advanced interpolation method, because the image resolution differed significantly between sequences, patients, and centers. Furthermore, in order to build a consensus segmentation from multiple manual annotations, we devised a simple fusion rule that explicitly respects the known spatial and-with respect to the evolution of the disease-temporal relations between the tumor substructures, as more advanced fusion schemes were found to yield implausible results. These choices can certainly be criticized; however, we believe the major challenge for the segmentation algorithms was ultimately not interpolation or label fusion details, but rather the large spatial and structural variability of the tumors in the BRATS dataset, as well as the variability in image intensities arising from differences in imaging equipment and acquisition protocols.</p><p>Although we were able to identify several overall "winning" algorithmic properties (discussed in Section V-C), one general limitation of image analysis benchmarks is that it is often difficult to explain why a particular algorithm does well or-even more difficult-why it does not do well. This is because even the best algorithmic pipeline will fail if just one element is badly parameterized or implemented. Detecting such failures would require a meticulous study of each element of every processing pipeline-for a learning-based approach, for example, of the intensity normalization, the feature extraction, the classification algorithm, and the spatial regularization. Unfortunately, while this type of analysis is extremely valuable, it requires a careful experimental design that cannot easily be pursued post hoc on a heterogeneous set of algorithms contributed by different parties in a competitive benchmark such as BRATS.</p><p>Another limitation of the current study, which is also shared by other benchmarks, pertains to the selection of an appropriate overall evaluation metric that can be used to explicitly rank all competing algorithms. Although we reported separate results for sensitivity, specificity, and Hausdorff distance, we based our overall final ranking in different tumor regions on average Dice scores. As demonstrated by the results of the Festa method in "active tumor" segmentation, however, the exact choice of evaluation metric does sometimes affect the ranking results, as different metrics are sensitive to different types of segmentation errors.</p><p>Although the number of images included in the BRATS benchmark was large, the ranking of the segmentation algorithms reported here may still have been impacted by the high variability in brain tumors. As such, it will be desirable to further increase the number of training and test cases in future brain tumor segmentation benchmarks.</p><p>We wish to point out that all the individual segmentation results by all participants are publicly available, <ref type="bibr" target="#b41">9</ref> so that groups interested in brain tumor segmentation can perform their own internal evaluation, focusing specifically on what they consider most important. Looking at individual segmentations can also help understand better the advantages and drawbacks of the different algorithms under comparison, and we would strongly encourage taking advantage of this possibility. It is worth pointing out that the individual rater's manual segmentations of the training data are also available, <ref type="bibr" target="#b42">10</ref> so that groups that do not trust the consensus labels we provide, can generate their own training labels using a fusion method of their choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Lessons Learned</head><p>There are lessons that we learned from organizing BRATS and 2013 that may also be relevant for future benchmark organizers confronted with complex and expensive annotation tasks. First, it may be recommended to generate multiple annotations for the test data-rather than for the training set as we did here-as this is where the comparisons between experts and algorithms take place. Many algorithms will be able to overcome slight inconsistencies or errors in the training data that are present when only a single rater labels each case. At the same time, most algorithms will benefit from having larger training datasets and, hence, can be improved by annotating larger amounts of data even if this comes at the price of fewer annotations per image volume.</p><p>Second, while it may be useful to make unprocessed data available as well, we strongly recommend providing participants with maximally homogenized datasets-i.e., image volumes that are co-registered, interpolated to a standard resolution and normalized with respect to default intensity distributions-in order to ease participation, maximize the number of participants, and facilitate comparisons of the segmentation methods independently of preprocessing issues. <ref type="bibr" target="#b41">9</ref> www.virtualskeleton.ch/BRATS/StaticResults2013 10 www.virtualskeleton.ch/ BRATS 2013 "BRATS 2013 Individual Observer Ground-truth Data"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Future Work</head><p>Given that many of the algorithms that participated in this study offered good glioma segmentation quality, it would seem valuable to have their software implementations more easily accessible. Right now, only an implementation of Bauer and Meier's method is freely available, <ref type="bibr" target="#b43">11</ref> and Tustison's code <ref type="bibr" target="#b44">12</ref> The online MIDAS and VSD platforms that we used for BRATS may be extended to not only host and distribute data, but also to host and distribute such algorithms. Making the top algorithms available through appropriate infrastructures and interfaces-for example as developed for the VISCERAL benchmark <ref type="bibr" target="#b45">13</ref>  <ref type="bibr" target="#b118">[86]</ref>, or as used in the commercial NITRC Amazon cloud service <ref type="bibr" target="#b46">14</ref> -may help to make thoroughly benchmarked algorithms available to the wider clinical research community.</p><p>Since our results indicate that current automated glioma segmentation methods only reach the level of consensus-rater variation in the "whole" tumor case ( <ref type="figure" target="#fig_5">Fig. 8</ref>), continued algorithmic development seems warranted. Other tumor substructures may also be relevant with respect to diagnosis and prognosis, and a more refined tumor model-with more than the four classes used in this study-may be helpful, in particular when additional image modalities are integrated into the evaluation. Finally, in clinical routine the change of tumor structures over time is often of primary relevance, something the current BRATS study did not address. Evaluating the accuracy of automated routines in longitudinal settings including both pre-and postoperative images, are important directions for future work along with further algorithmic developments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. SUMMARY AND CONCLUSION</head><p>In this paper we presented the BRATS brain tumor segmentation benchmark. We generated the largest public dataset available for this task and evaluated a large number of state-of-the-art brain tumor segmentation methods. Our results indicate that, while brain tumor segmentation is difficult even for human raters, currently available algorithms can reach Dice scores of over 80% for whole tumor segmentation. Segmenting the tumor core region, and especially the active core region in high-grade gliomas, proved more challenging, with Dice scores reaching 70% and 60%, respectively. Of the algorithms tested, no single method performed best for all tumor regions considered. However, the errors of the best algorithms for each individual region fell within human inter-rater variability.</p><p>An important observation in this study is that fusing different segmenters boosts performance significantly. Decisions obtained by applying a hierarchical majority vote to fixed groups of algorithmic segmentations performed consistently, for every single segmentation task, better than the best individual segmentation algorithm. This suggests that, in addition to pushing the limits of individual tumor segmentation algorithms, future gains (and ultimately clinical implementations) may also be obtained by investigating how to implement and fuse several <ref type="bibr" target="#b43">11</ref> www.nitrc.org/projects/bratumia <ref type="bibr">[</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Here we reproduce a short summary of each algorithm used in BRATS 2012 and BRATS 2013, provided by its authors. A more detailed description of each method is available in the workshop proceedings. <ref type="bibr" target="#b47">15</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BAUER, WIEST AND REYES (2012): SEGMENTATION OF BRAIN TUMOR IMAGES BASED ON INTEGRATED HIERARCHICAL CLASSIFICATION AND REGULARIZATION</head><p>Algorithm and Data: We are proposing a fully automatic method for brain tumor segmentation, which is based on classification with integrated hierarchical regularization <ref type="bibr" target="#b119">[87]</ref>. It subcategorizes healthy tissues into CSF, WM, GM and pathologic tissues into necrotic, active, non-enhancing and edema compartment. The general idea is based on a previous approach presented in <ref type="bibr" target="#b75">[43]</ref>. After pre-processing (denoising, bias-field correction, rescaling and histogram matching) <ref type="bibr" target="#b106">[74]</ref>, the segmentation task is modeled as an energy minimization problem in a conditional random field (CRF) formulation. The energy consists of the sum of the singleton potentials in the first term and the pairwise potentials in the second term of (1). The expression is minimized using <ref type="bibr" target="#b120">[88]</ref> in a hierarchical way <ref type="bibr" target="#b33">(1)</ref> The singleton potentials are computed according to <ref type="bibr" target="#b34">(2)</ref>, where is the label output from a classifier, is the feature vector and is the Kronecker-function <ref type="bibr" target="#b34">(2)</ref> We use a decision forest as a classifier <ref type="bibr" target="#b121">[89]</ref>, which has the advantage of being able to handle multi-class problems and providing a probabilistic output <ref type="bibr" target="#b121">[89]</ref>. The probabilistic output is used for the weighting factor in (2), in order to control the degree of spatial regularization. A 44-dimensional feature vector is used for the classifier, which combines the inten-sities in each modality with the first-order textures (mean, variance, skewness, kurtosis, energy, entropy) computed from local patches, statistics of intensity gradients in a local neighborhood and symmetry features across the mid-sagittal plane. The pairwise potentials account for the spatial regularization. In <ref type="formula">3</ref>is a weighting function, which depends on the voxel spacing in each dimension. The term penalizes different labels of adjacent voxels, while the intensity term regulates the degree of smoothing based on the local intensity variation, where PCD is a pseudo-Chebyshev distance and is a generalized mean intensity.</p><p>allows us to incorporate prior knowledge by penalizing different tissue adjacencies individually <ref type="formula">3</ref>Computation time for one dataset ranges from 4 to min depending on the size of the images, most of the time is needed by the decision forest classifier.</p><p>Training and Testing: The classifier was trained using 5-fold cross-validation on the training dataset, with separate training for high-and low-grade as well as synthetic and patient data. The parameters of the algorithm were chosen empirically. We also compared the proposed approach to our previous method <ref type="bibr" target="#b75">[43]</ref> which used SVMs as a classifier instead of decision forests and which had a less sophisticated regularization. With the new method, the computation time could be reduced by more than a factor of two and the accuracy was significantly improved. However, we still discovered difficulties with datasets that were very different from the training data, which hints at some problems of the supervised algorithm with generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BUENDIA, TAYLOR, RYAN AND JOHN (2013): A GROUPING ARTIFICIAL IMMUNE NETWORK FOR SEGMENTATION OF TUMOR IMAGES</head><p>Algorithm and Data: GAIN+ is an enhanced version of the original Grouping Artificial Immune Network that was developed for fully automated MRI brain segmentation. The model captures the main concepts by which the immune system recognizes pathogens and models the process in a numerical form. GAIN+ was adapted to support a variable number of input patterns for training and segmentation of tumors in MRI brain images. The model was demonstrated to operate with multi-spectral MR data with an increase in accuracy compared to the single spectrum case. The new input patterns include, in any combination, voxel intensities from 2D or 3D blocks or shapes of varying sizes customized to each MRI sequence (T1, T2, FLAIR, etc.), and also include feature and textural patterns such as mean and variance of selected block sizes, slice or radial distance, co-occurrence matrices, among others. Due to the representation of the voxel intensities as multi-bit values, it can be shown that not every bit carries the same entropy. That is, each bit does not contribute equally to the final interpretation of the data. The GAIN algorithm makes use of this fact to increase the speed of its operation. Bits are grouped into groups of size 2 bits. A new grouping approach was implemented based on the location of each bit within the input pattern, and the significance of the input features. Higher priority was given to higher order bits and overall to voxels at closer distance to the center voxel. This grouping approach runs in just a few seconds and the same grouping file can be used for all cases. Training takes an average of 1.3 min per input byte, thus, for example, an input pattern of 16 bytes takes an average of 21 min of training. Segmentation with post-processing of one case takes 20 s for the same input size. The preprocessing pipeline was designed to remove noise and inhomogeneities due to MR scanner bias fields, and match each spectrum's intensity histogram to the volumes used for training. Several post-processing options were added to the program, such as finding and extracting connected components, and performing dilation and erosion on those components.</p><p>Training and Testing: The original GAIN method was designed to train on a single case, and although GAIN+ has been adapted to train on multiple images, single case training performed best. We performed 20-fold cross validation on the real high-grade BRATS 2013 training set. GAIN+ performance was evaluated with the four BRATS 2013 labels: 1) Necrosis, 2) Edema, 3) Non-Enhancing tumor, and 4) Enhancing Tumor. In this case, GAIN+ was run with an input pattern of 16 bytes:</p><p>voxels. The segmented images were uploaded to the BRATS 2013 Virtual Skeleton web site. The evaluation was done for three different tumor sub-compartments: 1) Region 1: Complete tumor (labels for patient data), Dice: 0.73, 2) Region 2: Tumor core (labels for patient data), Dice: 0.61, 3) Region 3: Enhancing tumor (label 4 for patient data), Dice: 0.64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CORDIER, MENZE, DELINGETTE AND AYACHE (2013): PATCH-BASED SEGMENTATION OF BRAIN TISSUES</head><p>Algorithm and Data: We describe a fully automated approach inspired by the human brain labelling method described in <ref type="bibr" target="#b122">[90]</ref>, and similar to multi-atlas label propagation methods <ref type="bibr" target="#b123">[91]</ref>- <ref type="bibr" target="#b125">[93]</ref>. A database of multi-channel local patches is first built from a set of training pathological cases. Then, given a test case, similar multi-channel patches are retrieved in the patch database, along with the corresponding labels. Finally, a classification map for the test case is inferred as a combination of the retrieved labels during a label fusion step <ref type="bibr" target="#b126">[94]</ref>- <ref type="bibr" target="#b129">[97]</ref>.</p><p>To decrease the computation time, images are sub-sampled to 2-mm isotropic resolution <ref type="bibr" target="#b130">[98]</ref>. A candidate tumor mask is defined by thresholding (50% percentile) a denoised <ref type="bibr" target="#b131">[99]</ref> -weighted FLAIR image. Since the patch retrieval is driven by a sum-of-squared-differences (SSD), a global intensity alignment <ref type="bibr" target="#b130">[98]</ref> is applied to the mean image intensity restricted to the candidate tumor mask. Training images are cropped along the Z-axis to focus on training patches surrounding the tumor.</p><p>Image features are the concatenation of 3 3 3 intensity patches extracted from four MR channels. Given a multi-channel patch query, the five nearest-neighbor patches are retrieved within each training patch database, each of which contributes to a weighted voting. We use exponential weights, based on patch similarity <ref type="bibr" target="#b122">[90]</ref>, <ref type="bibr" target="#b127">[95]</ref>, <ref type="bibr" target="#b129">[97]</ref>; the decay parameter depends on the test case, and is set to the maximum of SSD between every voxel in the test case and every first-neighbor training patch. For each label, the weighted voting results in a probability-like map. Since the label regions are interlocked, label maps are hierarchically computed: first, complete tumor is distinguished from healthy tissues; then tumor core from edema; finally enhancing tumor from the rest of the core. At each step, weighted votes are rebalanced based on label frequencies, in order to penalize labels which would be more often picked if the patch retrieval were blind. As post-processing, at most the two biggest connected components of the complete tumor are kept, the second one being kept only if its volume is greater than 20% of the volume of the first one. Classification maps are up-sampled to 1-mm isotropic resolution, and one iteration of Iterated Conditional Modes <ref type="bibr" target="#b132">[100]</ref> smooths the result. On average, the segmentation total computation time is 20 min times the number of training cases.</p><p>Training and Testing: The most important parameters are manually set and consist of the patch size and the number of training cases. A range of values for the number of retrieved nearest-neighbor patches were tested, and the segmentation results were almost not affected. For the training data, the labelling is performed in a leave-one-out scheme, while for the test data, every relevant training case is used. Real cases are processed separately from simulated cases. For real low-grade test cases, the training dataset includes both high-and low-grade cases, while for real high-grade test cases, the training dataset only includes high-grade cases.</p><p>The algorithm shows a few shortcomings which would require the following steps to be refined.</p><p>• The necrotic core is sometimes partially missed by the candidate tumor mask. Tumour detection could either be skipped at the expense of higher computational burden, or be more sensitive by using the -weighted image in addition to the FLAIR image. • For enhancing tumors, thin parts are often missed by the algorithm. This is visible on the probability maps and may be due to the sub-sampling step. • Tumor voxels can be misclassified as healthy tissues or edema, usually if the necrotic core is similar to the cerebrospinal fluid on the FLAIR channel. Enforcing the convexity of tumor connected components helps but the contours of the tumor compartments are not matched as closely. The regularization would be more relevant during the label fusion. • Shape criteria could help discard false positives in the occipital lobe and the cerebellum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DOYLE, VASSEUR, DOJAT AND FORBES (2013): FULLY AUTOMATIC BRAIN TUMOR SEGMENTATION FROM MULTIPLE MR SEQUENCES USING HIDDEN MARKOV FIELDS AND VARIATIONAL EM</head><p>Algorithm and Data: We propose an adaptive scheme for brain tumor segmentation using multiple MR sequences. Our approach is fully automatic and requires no training. The model parameters are instead estimated using a variational EM algorithm with MRF constraints and the inclusion of a priori probabilistic maps to provide a stable parameter trajectory during optimization.</p><p>We build on the standard hidden Markov field model by considering a more general formulation that is able to encode more complex interactions than the standard Potts model. In particular, we encode the possibility that certain tissue combinations in the neighborhood are penalized more than others, whereas the standard Potts model penalizes dissimilar neighboring classes equally, regardless of the tissues they represent.</p><p>A solution to the model is found using the Expectation Maximization (EM) framework <ref type="bibr" target="#b133">[101]</ref> combined with variational approximation for tractability in the presence of Markov dependencies. In particular, we consider the so-called mean field principle that provides a deterministic way to deal with intractable Markov Random Field (MRF) models <ref type="bibr" target="#b134">[102]</ref> and has proven to perform well in a number of applications.</p><p>We adopt a data model comprising of five normal tissue classes; white matter, grey matter, ventricular CSF, extraventricular CSF, and other. The glioma is modeled by a further four classes representing the diseased tissue state; edema, non-enhancing, enhancing and necrotic. In the absence of sufficient data to robustly and accurately estimate a full free interaction matrix with the number of classes , further constraints are imposed on the . The four glioma classes are considered a single structure, whose interaction with the normal tissue classes is not dependant on the specific glioma tissue state. Parameters are estimated using the variational EM algorithm, which provides a tractable solution for non trivial Markov models.</p><p>The deformable transform that describes the mapping between the International Consortium for Brain Mapping (ICBM) template and the data space is found using tools provided by the Insight Segmentation and Registration Toolkit (ITK). The transform is used to register the probabilistic tissue atlases to the MR sequences. An initial 5-class segmentation is performed, and the tumor region of interest (ROI) is detected by a simple morphological method comparing the segmentation result and the five tissue atlases. The prior probabilistic tissue atlas and the tumor ROI are incorporated a priori in the final segmentation algorithm via the singleton potential parameter in the MRF.</p><p>The computation time is 30 min per patient, giving an average Dice coefficient for high-grade and low-grade complete tumor volume of 0.84 and 0.81, respectively.</p><p>Training and Testing: The algorithm was tested on real-patient data from the BRATS 2012 and 2013 dataset. No training was performed; the initial labeling was random, and all model parameters were estimated iteratively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FESTA, PEREIRA, MARIZ, SOUSA AND SILVA (2013): AUTOMATIC BRAIN TUMOR SEGMENTATION OF MULTI-SEQUENCE MR IMAGES USING RANDOM DECISION FORESTS</head><p>Algorithm and Data: The proposed algorithm is fully automated and uses all available MRI sequences. Three preprocessing steps were performed. The first aims for the bias field correction, with N4ITK method <ref type="bibr" target="#b135">[103]</ref>. The second normalizes the intensity scale of each sequence to a chosen reference, by histogram matching using ITK <ref type="bibr" target="#b136">[104]</ref>. Finally, since some FLAIR images were already limited to the volume of interest, all sequences from each subject were cropped to have the same brain volume. A random decision forest is used to classify each brain voxel, based on several features extracted from the training data. The main parameters in a decision forest are the number of trees and their depth, set to 50 and 25, respectively. Due to computational limitations, a maximum of points per training subject were sampled. Half of these points are background and the other half are tumor and edema. The feature set includes: 1) MR sequences intensities and the difference between each two sequences; 2) neighborhood information with the mean, sum, median and intensity range of 3D cubic neighborhoods with edges of 3, 9, and 19 mm, centered in each voxel, from all MR sequences and the differences between sequences; 3) context information as the difference between each voxel and the mean value of 3 3 3 mm cubes, centered 3 mm from the voxel in six directions (two per axis), from all sequences; 4) texture information in all MR sequences, including edge density and local binary partition (signal and magnitude) extracted from 3 3 mm neighborhoods, and the Laws texture features <ref type="bibr" target="#b137">[105]</ref> extracted from 2D 3 neighborhoods, in all three dimensions. Finally, a post processing step was performed assuming that very small isolated 3D regions, with less than seven voxels (value found empirically), of one label type should not exist. The total execution time is about 30 min for each test subject, mainly due to the features extraction, using the programming language Python on a computer with an Intel processor (i7-3930k, 3.2 GHz).</p><p>Training and Testing: Three datasets were available: "Training" (with corresponding ground truth), "LeaderBoard" and "Challenge." The training step was done using all real data from the Training dataset, from both grades to increase the representation of some labels (like non-enhancing). The testing step was performed with all datasets. Leave-one-out cross-validation was used for the Training dataset. The features set, as well as the hyperparameters for the decision forest, were found using leave-one-out cross-validation of the Training dataset. To segment high-grade tumors, all images (used in training and testing stages) were normalized to a high-grade reference. Similarly, images were normalized to a low-grade reference when segmenting these tumors. The critical part of the proposed algorithm is the normalization, which influences the whole pipeline, especially with intensity related features used in a supervised classifier. A basic characterization of texture was used in the proposed algorithm and it seems to be helpful in the distinction of different tumor tissues. With a better texture characterization, it is expected to achieve further improvement in the segmentation of brain tumors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GEREMIA, MENZE AND AYACHE (2012): SPATIAL DECISION FORESTS FOR GLIOMA SEGMENTATION IN MULTI-CHANNEL MR IMAGES</head><p>Medical imaging protocols produce large amounts of multi-modal volumetric images. The large size of the produced datasets contributes to the success of machine learning methods. These methods automatically learn from the data how to perform challenging task such as, for instance, semantic annotation. Although being a tremendous asset in theory, very large datasets are down-sampled to ensure tractability of the learning process. Moreover, the informative data is often submerged in overwhelming amounts of redundant data. Thus, most state of the art methods need to parse large amounts of uninformative data before reaching valuable data.</p><p>We present the "Spatially Adaptive Random Forests" (SARFs) <ref type="bibr" target="#b74">[42]</ref> to overcome these issues in the context of volumetric medical images. SARFs automatically learn how to efficiently target valuable data. It avoids parsing and processing redundant data while focusing its computational power on critical image regions. We demonstrate its power to address multi-class glioma annotation in multi-modal brain MRIs.</p><p>SARF builds on three cutting-edge methods: 1) discriminative random forests, 2) an efficient multi-scale 3D image representation, and 3) structured labelling. Random forests demonstrated outstanding segmentation results in the context of brain lesion segmentation in MRIs and multi-organ segmentation in full body CT scans. Although real-time performance can be achieved during testing, training the forest is still time consuming due to the large amount of data that it needs to ingest.</p><p>In order to speed up training and testing, SARF relies on an efficient hierarchical representation of image volumes. The hierarchical representation is obtained by recursively applying an extended version of the SLIC algorithm to handle volumetric multi-modal images. The final result consists in a coarse to fine super-voxel hierarchical partition of the images similar to (cite bouman et al.).</p><p>Rather than merging the segmentations obtained from the different scales of the image, SARF iteratively refines the segmentation. This is made possible by carefully extrapolating the voxel-based ground truth to coarser scales. Additionally, SARF provides the ability of reasoning on semantically close classes by combining them in an hierarchical way (cite structured labelling). The resulting semantic tree together with the supervoxel hierarchy are powerful tools to efficiently parse and annotate the image volumes.</p><p>SARF makes use of these tools by integrating them into the random forest framework. During training, it learns the optimal image spatial sampling associated to the segmentation task. During testing, the algorithm quickly handles the background and focuses on challenging image regions to refine the segmentation. These properties were demonstrated together with promising results in the context of multi-class glioma segmentation in multi-modal brain MRIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GUO, SCHWARTZ AND ZHAO (2013): SEMI-AUTOMATIC SEGMENTATION OF MULTIMODAL BRAIN TUMOR USING ACTIVE CONTOURS</head><p>In this paper, we present a semi-automatic segmentation method for multimodal brain tumors. It requires only that a user manually draw a region of interest (ROI) roughly surrounding the tumor on a single image. The algorithm combines the image analysis techniques of region and edge-based active con-tours and level set approach, and has the advantages of easy initialization, quick segmentation, and efficient modification. The <ref type="figure">Fig. 10</ref>. Maximum diameter line drawn by the user to initialize the algorithm for CE-T1 (a), T2 (b), and Flair (c) modalities and the corresponding outputs, for a sample high-grade case. Manual labels overlayed on T1 for a sample slice (d).</p><p>typical run-time for each case in the training dataset can be within 1 min.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HAMAMCI AND UNAL (2012): MULTIMODAL BRAIN TUMOR SEGMENTATION USING THE "TUMOR-CUT" METHOD</head><p>Algorithm and Data: As described in detail in the "Tumor-cut" article <ref type="bibr" target="#b104">[72]</ref>, the semi-automatic tumor segmentation method by Hamamci and Unal specifically targets the gross tumor volume (GTV) and the necrotic regions of the brain tumors on contrast enhanced T1-weighted MR images, requiring an initialization by drawing a line through the maximum diameter of the tumor as in the "Response Evaluation Criteria In Solid Tumors" (RECIST) guidelines <ref type="bibr" target="#b36">[4]</ref>. For the BRATS challenge, the method was extended to multi-modal MRI to include also the labels for edema and non-enhanced regions. Hamamci and Unal's approach to fuse different MR modalities is to apply the original tumor-cut method to each channel seperately and then combine the segmented volumes by basic set operations based on the type of the modality. For each channel, a segmentation is initialized by drawing the maximum observable diameter of the tumor and performed independently (see <ref type="figure">Fig. 10</ref>). For FLAIR images, whole hyper-intense region is segmented as FLAIR volume and for T2 images only the core abnormality is segmented as T2 volume . Tumor core is segmented on contrast enhanced T1 MRI followed by the application of the necrotic segmentation method to segment the necrotic regions within the tumor core . For the low-grade cases, and are set to empty, because the tumors were not enhanced by the application of the contrast agent. Non-contrast enhanced T1 MR images were used neither for high-nor low-grade cases. For FLAIR segmentation, only the weight of the regularizer in the energy term for the level-set evolution is tuned to allow resulting tumor surfaces to have higher curvatures. Label for each class is determined by the following operations:</p><p>For each case, user interaction takes about 1-2 min and typical run time is around 10-30 min, depending on the size of the tumor, using a CPU. However, the parallel nature of the algorithm allows GPU implementation, which would reduce the processing time significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Testing:</head><p>We observed that in one case only, we segmented an abnormal structure, which was not labeled as tumor by the experts. Although, this resulted a zero overlap score for the particular case, in fact, to allow user to choose what to segment is an advantage of the semi-automatic approach. In general, the T2 results did not provide useful information, as only a small portion of the tumors consist of the non-enhancing region and the segmentation results were not accurate due to the low contrast between tumor core and edema. The approach of Hamamci and Unal's algorithm was to apply their original algorithm independently to each modality. A combined algorithm that considers the multidimensional information from all available modalities have the potential to improve the results obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MEIER, BAUER, SLOTBOOM, WIEST AND REYES (2013): APPEARANCE-AND CONTEXT-SENSITIVE FEATURES FOR BRAIN TUMOR SEGMENTATION</head><p>Algorithm and Data: In our approach, we regard image segmentation as a supervised classification problem. The present method is an improved version of the one proposed by Bauer et al. in <ref type="bibr" target="#b119">[87]</ref> and can be subdivided into three main parts: a feature extraction yielding a voxel-wise feature vector, a classification step and a subsequent spatial regularization. Moreover, we preprocess the multimodal image data which encompasses noise-reduction, bias-field correction and intensity normalization.</p><p>The major difference to <ref type="bibr" target="#b119">[87]</ref> is that for every voxel we extract a 257-dimensional feature vector composed of appearancesensitive (multimodal intensities and intensity differences, firstorder textures and gradient textures) and context-sensitive features (atlas-normalized coordinates, multiscale symmetry features and multi-/monomodal ray features). As a classifier we employ a classification forest. The predicted class label is defined according to the MAP-rule applied on the posterior probability output from the classification forest. The implementation of the classification forest is based on the Sherwood library <ref type="bibr" target="#b78">[46]</ref>. The regularization is conducted in a hierarchical manner as proposed in <ref type="bibr" target="#b138">[106]</ref>. It is realized as an energy minimization problem of a conditional random field, which is defined on a grid graph representing the image. The probabilistic output of the classification forest is further used to define the unary potentials, which model the affiliation of a voxel to a possible tissue class. Pairwise potentials model the coherence between neighboring voxels and are used to incorporate tissue dependencies and to account for anisotropic voxel dimensions. For solving the energy minimization problem we relied on the Fast-PD algorithm proposed in <ref type="bibr" target="#b120">[88]</ref>.</p><p>Our method is fully automatic with a testing time of 2-12 min per subject depending on the size of the image volume, where the feature extraction consumes most of the time.</p><p>Training and Testing: Relevant parameters of the classification forest (depth, number of candidate weak learners and thresholds per node) are set according to a gridsearch. The model is trained either on high-grade or low-grade cases only. For preliminary results and training phase before the competition the method has been evaluated on the high-grade or low-grade cases of the BRATS2013 training set using 5-fold cross validation.</p><p>We observed that depending on the image data false positives in the infratentorial part of the brain might appear. Moreover, the discrimination between edema and non-enhancing tumor seems to be the most challenging one. We plan to employ additional image features to overcome these problems and to further improve the current accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MENZE, VAN LEEMPUT, LASHKARI, WEBER, AYACHE AND GOLLAND (2012): SEGMENTING GLIOMA IN MULTI-MODAL IMAGES USING A GENERATIVE MODEL FOR BRAIN LESION SEGMENTATION</head><p>We evaluate a fully automated method for channel-specific tumor segmentation in multi-dimensional images proposed by us in <ref type="bibr" target="#b105">[73]</ref> that extends the general "EM segmention" algorithm for situations when specific spatial structures cannot be described sufficiently through population priors. The method represents a tumor appearance model for multi-dimensional sequences that provides channel-specific segmentation of the tumor. Its generative model shares information about the spatial location of the lesion among channels while making full use of the highly specific multi-modal signal of the healthy tissue classes for segmenting normal tissues in the brain. In addition to tissue types, the model includes a latent variable for each voxel encoding the probability of observing tumor at that voxel, based on the ideas from <ref type="bibr" target="#b87">[55]</ref>, <ref type="bibr" target="#b88">[56]</ref>.</p><p>• Approach amends physiological tissue atlas with personalized lesion prior. • During segmentation information on tumor localization is traded between modalities via latent prior. Results in an individual segmentation in every modality. • Outperforms both univariate and multivariate EM segmentation and is capable of considering channel-specific constraint on hypo-or hypo intensity of the lesion with respect to the intensities of normal tissues in the same image. To initialize our algorithm we segment the volume into the three healthy and an outlier class using a freely available implementation of the EM segmentation with bias correction <ref type="bibr" target="#b57">[25]</ref>. Outliers are defined as being more than three standard deviations away from the centroid of any of the three normal tissue classes. We apply our algorithm to the bias field corrected volumes returned from this EM segmenter and initialize intensity parameters with values estimated in the initial segmentation. We initialize the latent atlas to 0.7 time the local prior for the presence of gray or white matter. For a semantic interpretation that is in line with the class definitions of the segmentation challenge, Channels-specific segmentations returned by our algorithm are transformed to Edema and Core classes. We label voxels that show tumor specific changes in the T2 channel as edema, and voxels that show hyper-intense tumor specific changes as tumor core. A discriminative classifier filters all tumor segments removing those that are most likely to be false positives, primarily evaluating shape and location of the tumor regions returned from the generative model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MENZE, GEREMIA, AYACHE AND SZEKELY (2012): SEGMENTING GLIOMA IN MULTI-MODAL IMAGES USING A GENERATIVE-DISCRIMINATIVE MODEL FOR BRAIN LESION SEGMENTATION</head><p>The present discriminative model <ref type="bibr" target="#b105">[73]</ref> (described above) returns probability maps for the healthy tissues, and probability maps for the presences of characteristic hypo-or hyper-intense changes in each of the image volumes. While this provides highly specific information about different pathophysiological processes induced by the tumor, the analysis of the multimodal image sequence may still require to highlight specific structures of the lesion-such as edema, the location of the active or necrotic core of the tumor, "hot spots" of modified angiogenesis or metabolism-that cannot directly be associated with any of these basic parameter maps returned. As a consequence, we propose to use the probabilistic output of the generative model, together with few structural features that are derived from the same probabilistic maps, as input to a classifier modeling the posterior of the desired pixel classes. In this we follow the approach proposed by <ref type="bibr" target="#b72">[40]</ref> that prove useful for identifying white matter lesion in multiple input volumes. The building blocks of this discriminative approach are the input features, the parametrization of the random forest classifier used, and the final post-processing routines.</p><p>The approach combines advantageous properties from both types of learning algorithms: First, it extracts tumor related image features in a robust fashion that is invariant to relative intensity changes by relying on a generative model encoding prior knowledge on expected physiology and pathophysiological changes. Second, it transforms image features extracted from the generative model-representing tumor probabilities in the different image channels-to an arbitrary image representation desired by the human interpreter through an efficient classification method that is capable of dealing with high-dimensional input data and that returns the desired class probabilities. In the following, we shortly describe the generative model from <ref type="bibr" target="#b105">[73]</ref>, and input features and additional regularization methods used similar to our earlier discriminative model from <ref type="bibr" target="#b72">[40]</ref>.</p><p>As input feature describing the image in voxel we use the probabilities for the tissue classes . We also use the tumor probability for each channel , and the image intensities after calibrating them with a global factor that has been estimated from gray and white matter tissue</p><p>. From these data we derive two types of features: the "long range features" that calculate differences of local image intensities for all three types of input features ( , ), and a distance feature that calculates the geodesic distance of each voxel to characteristic tumor areas. We choose random forests as our discriminative model as it uses labeled samples as input and returns class probabilities. For the normal classes (that are not available from the manual annotation of the challenge dataset) we infer the maximum a posterior estimates of the generative model and use them as label during training. Random forests learn many decision trees from bootstrapped samples of the training data, and at each split in the tree they only evaluate a random subspaces to find the best split. To minimize correlation in the training data, and also to speed up training, we draw no more 2000 samples from each of the voxels in each of the 25 dataset. We train an ensemble with 300 randomized decision trees, and choose a subspace dimensionality of 10. We use the random forest implementation from Breiman and Cutler. To improve segmentation, we use a Markov random field (MRF) imposing a smoothness constraint on the class labels. We optimize the function imposing costs when assigning different labels in a six neighborhood on the cross-validated predictions on the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REZA AND IFTEKHARUDDIN (2013): MULTI-CLASS ABNORMAL BRAIN TISSUE SEGMENTATION USING TEXTURE FEATURES</head><p>Algorithm and Data: In this work, we propose fully automated multi-class abnormal brain tissue segmentation in multimodality brain MRI. <ref type="figure" target="#fig_8">Fig. 11</ref> shows a generic flow diagram for our algorithm pipeline. Since BRATS-2013 dataset is already skull stripped and co-registered; the first step involves preprocessing of 2D MRI slices extracted from 3D volume for each patient. Intensity normalization and inhomogeneity correction are used as pre-processing steps. Then two primary sets of features are extracted from each preprocessed image. The first set includes non-local features such as pixel intensities and differences of intensities that represents global characteristics of brain tissues. To characterize the tumor surface variation, we employ our novel texture features such as fractal PTPSA <ref type="bibr" target="#b139">[107]</ref>, and mBm <ref type="bibr" target="#b140">[108]</ref> as well as classical textons <ref type="bibr" target="#b141">[109]</ref> as the second set of features. After extraction, all features are fused in a classical Random Forest <ref type="bibr" target="#b142">[110]</ref> classifier. Once the labels are predicted simultaneously, we obtain a 3D volume image per patient for online evaluation.</p><p>Training and Testing: We performed 3-fold cross validation on training dataset to tune the parameters. Extensive experiments suggests employing all tumor samples and randomly selected equal number of non-tumor samples for training the RF classifier yields good training results. For a single patient it takes about an hour and half to complete the whole process as shown in <ref type="figure" target="#fig_8">Fig. 11</ref> while 3-fold cross-validation takes only about 15 min. The most time consuming parts are preprocessing and feature extraction which are done offline. All results in this work are obtained using MATLAB 2011a on windows 64 bit 2.26 GHz Intel Xeon processor, with 12 GB RAM. We process HG and LG patients separately for both Leader Board and Challenge testing phases. There are a few leader board cases that show low scores. Our observation suggests that if the tumor tissue intensities are below the mean intensity of the image, the necrosis tissues are misclassified as non-tumor. Data redundancy in the samples and covariance among the features usually lower the classifier performance. In summary, our extensive experimental results with BRATS data confirm the efficacy of our texture-based methods for multi-class abnormal brain tissue segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RIKLIN RAVIV, VAN LEEMPUT AND MENZE (2012): MULTI-MODAL BRAIN TUMOR SEGMENTATION</head><p>VIA LATENT ATLASES</p><p>The work is based on a generative approach for patient-specific segmentation of brain tumors across different MR modalities much in the spirit of <ref type="bibr" target="#b87">[55]</ref>, <ref type="bibr" target="#b88">[56]</ref>. The segmentation problem is solved via a statistically driven level-set framework. Specifically, image partitioning into regions of interest (tumor parts) and healthy brain parts are obtained via the joint evolution of four level-sets functions determined by the images gray level-distributions and a smoothness term. Manual initialization based on a few mouse clicks to determine the approximate tumor center and extent was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHIN (2012): HYBRID CLUSTERING AND LOGISTIC REGRESSION FOR MULTI-MODAL BRAIN TUMOR SEGMENTATION</head><p>Unsupervised learning approaches have potential for applications in medical image processing, as previously discussed <ref type="bibr" target="#b143">[111]</ref>- <ref type="bibr" target="#b145">[113]</ref>. Additionally, the approach can be extended readily to a previously unseen dataset avoiding the issues of overfitting that can occur in supervised learning methods, where overfitting has a larger influence in tumor segmentation when tumors have very heterogeneous characteristics. Unsupervised learning approaches were applied 1) in <ref type="bibr" target="#b144">[112]</ref> for the previous two-class segmentation challenge, and 2) in <ref type="bibr" target="#b145">[113]</ref> to detect multiple organs from a dataset where a few roughly labeled samples were available. These methods however were not directly applicable when the format of this challenge was changed to classify four-class labels. The four-class segmentation problem was therefore approached with a supervised learning algorithm, used previously in <ref type="bibr" target="#b144">[112]</ref>, to segment the tumor-cores, trained with logistic regression. Four-dimensional patches (3 3 3 volume-patch channels) were used with second-order polynomial features as described in <ref type="bibr" target="#b144">[112]</ref>, as opposed to the three-dimensional patches ( 2-D image-patch temporal-dimension) used previously in <ref type="bibr" target="#b145">[113]</ref> to identify organs (but not for segmentation). This was because the dataset for this challenge was carefully registered with little motion, compared to the abdominal scans in <ref type="bibr" target="#b145">[113]</ref> where the registration over the 40 volumes along the time-course was difficult as the region is usually affected by breathing motion. Deep neural networks with up to six layers were tried as well, pre-training the hidden-layers with stackedautoencoder feature learning and subsequently fine-tuning them with the labeled samples in the training dataset. Neural network model was not used for the challenge however, because the improvement of classification accuracy was small relatively to the higher complexity compared to the logistic regression model. Each channel of volumes was normalized separately, to try to learn the relation between the multi-channel intensity values, and to avoid any biases in the image intensities in different scans. The same type of classifier was used to classify all labels including the not-of-interest label (label:0), where they were trained only on the patient-dataset which has four-class labels, and applied to synthetic data which has only two labels. Two cross-validations were performed for the parameter adaptation, and no additional post-processing steps were applied to the patch-wise classification. It took about 5-10 min to segment a volume depending on the size of the whole head in the volume, as the classifier scans through all the non-zero entities. The segmentation result is reasonably good, especially considering that only patch-wise classification was performed for the segmentation without any post-processing step, with a single (type of) classifier being used to segment all tumor classes and data-types (patient/synthetic). This demonstrates the application of a classification model applied to the segmentation of coarsely labeled tumors. Combining any post-processing steps might provide an immediate improvement on the final segmentation result, while application of unsupervised methods could be studied in the future for this four-class segmentation, e.g., segmenting label: x-vs-rest for all labels individually but similarly to <ref type="bibr" target="#b144">[112]</ref>. Extending the classification model to a structured prediction model is an interesting avenue for future work for this model, while using a whole volume as an input to deep convolutional neural networks <ref type="bibr" target="#b146">[114]</ref> might be worth investigating for the application of neural network models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUBBANNA, PRECUP, COLLINS AND ARBEL (2012): HIERARCHICAL PROBABILISTIC GABOR AND MRF SEGMENTATION OF BRAIN TUMOURS IN MRI VOLUMES</head><p>The off-site classification results were produced by a fully automated hierarchical probabilistic framework for segmenting brain tumours from multispectral human brain MRIs using multiwindow Gabor filters and an adapted Markov Random Field (MRF) framework <ref type="bibr" target="#b147">[115]</ref> (while the 2012 on-site results were produced by an earlier version of the work <ref type="bibr" target="#b148">[116]</ref>).</p><p>Image pre-processing involves bias field correction using N3 <ref type="bibr" target="#b149">[117]</ref>, intra-subject multispectral volume registration <ref type="bibr" target="#b150">[118]</ref>, non-uniformity correction <ref type="bibr" target="#b151">[119]</ref>, and intensity normalization <ref type="bibr" target="#b136">[104]</ref> The algorithm consists of two stages. At the first stage, the goal is to coarsely segment tumors (and associated sub-classes) from surrounding healthy tissues using texture features. During training, specialized Gabor functions are developed to optimally separate tumors from surrounding healthy tissues based on combined-space coefficients of tumors in multispectral brain MRIs <ref type="bibr" target="#b152">[120]</ref>. A Bayesian classification framework is designed such that models for tumour/non-tumors are built during training, based on the combined space Gabor decomposition. During testing, a Bayesian classifier results in tumour/non-tumor probabilities and coarse tumor boundaries around regions with high tumor probabilities. Prior probabilities for healthy brain tissues are obtained by registering a healthy tissue prior atlas to regions outside tumor boundaries <ref type="bibr" target="#b150">[118]</ref> The coarse boundaries are refined at the voxel level through a modified MRF framework that carefully separates different tumor subclasses from each other and from healthy tissues. This customized MRF differs from standard MRFs in that it is not simply a smoothing operator on priors. In addition to taking voxel intensities and class labels into account, it also models intensity differences between neighboring voxels in the likelihood model and considers transition probabilities between neighboring voxel classes. The second inference stage is shown to resolve local inhomogeneities and impose a smoothing constraint, while maintaining appropriate boundaries as supported by local intensity difference observations.</p><p>The method was trained and tested on the updated MICCAI BRATS Database, which included four tumor subclasses: necrotic core, edema, solid tumor, and enhanced tumor. The algorithm was trained and tested on clinical volumes, including low-grade and high-grade tumors. Classifiers were built separately for all categories. No other datasets were used for training or tuning. Online segmentation statistics (e.g., Dice overlap metrics) were provided. For training cases, the method was tested in a leave-one-out fashion. After training, the algorithm was tested on all test cases. On I7 Dell Optiplex machines, the training took a day, due to both convolution and simulated annealing algorithms used. Each volume took 70 min to classify, due to time consuming convolutions with different Gabor filters. For tumor core segmentation, the technique outperformed the top methods by about 30% in the clinical test cases in terms of Dice statistics, and had comparable performance with the highest performing methods in terms of segmentation of other tumour regions (in all statistics) for both training and test cases. In terms of shortcomings, the classifier is currently heavily dependent on the normalization step performing adequately, which caused a problem in at least one HG test case. In addition, should the classifier at the first stage fail to find tumours altogether, the second stage has difficulty recovering, as seen in an LG and HG case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TAYLOR, JOHN, BUENDIA AND RYAN (2013): MAP-REDUCE ENABLED HIDDEN MARKOV MODELS FOR HIGH THROUGHPUT MULTIMODAL BRAIN TUMOR SEGMENTATION</head><p>We have developed a novel Map-Reduce enabled extension to hidden Markov models (HMMs) to enable high-throughput training and segmentation of tumors and edema in multimodal magnetic resonance images of the brain.</p><p>Preprocessing and Training: Preprocessing prepares the input MR spectra, T1, T1 with Gadolinium contrast-enhanced (T1C), T2, and FLAIR, for segmentation. The preprocessing pipeline has been designed to remove spatial inhomogeneities due to patient movement, remove image artifacts (skull, eyes) not related to the segmentation problem, remove inhomogeneities due to MR scanner bias fields, and match each spectrum's intensity histogram to the volumes used for training. Training the HMM <ref type="figure" target="#fig_0">(Fig. 12)</ref> involves extracting a feature vector for each voxel in the source case. We extract intensity voxels from FLAIR, T1, T1C, and T2 MR spectra. Neighboring voxels are added to the feature vector. The corresponding truth labels for the voxel neighborhood in the feature vector is utilized for supervised training of the HMM. Extending the HMM model to Map-Reduce <ref type="figure" target="#fig_0">(Fig. 12)</ref> involved adapting the HMM supervised learning algorithm to incrementally update based on individual feature vectors and coding a Mapper to perform feature extraction. In our current case, a single Mapper handles a single training case, extracting all of the feature vectors for the case and providing the vectors to the Reducer. The Reducer collects the feature vectors from all of the Mappers and incrementally updates the HMM model as new feature vectors are produced. A final Controller normalizes the probabilities in the HMM (initial, transition, emission) and stores the HMM to a file. The HMM was trained with the BRATS 2013 high-grade training data.</p><p>Segmentation and Results: Segmenting with the HMM <ref type="figure" target="#fig_1">(Fig. 3)</ref> involves extracting the feature vector for each voxel in the target case in the same manner as HMM training. Voxels from FLAIR, T1, T1C, and T2 in a neighborhood around the voxel of interest are organized into the feature vector and provided to the trained HMM model. The HMM model produces a predicted label for the feature vector. Postprocessing involved filtering out small objects and applying dilation and erosion operations on each segmented class. Our method has been evaluated on the BRATS2013 challenge dataset for high-grade glioma cases. We achieve an mean accuracy (Dice score) of <ref type="bibr">[59.5]</ref>% for edema and <ref type="bibr">[65.6]</ref>% for tumor in the real cases. The Map-Reduce enabled HMM is able to train on all cases simultaneously, performing 220% faster on an 8-node cluster than on a single node. Segmentation of a single patient case takes less than min.</p><p>Limitations with the current algorithm include lack of support for spatial features, neighborhood-based textural features, and utilization of atlas-based priors, which have been shown to improve segmentation accuracy. We are currently working on a Decision Forest based extension to the HMM-Map Reduce algorithm to incorporate these features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TUSTISON, WINTERMARK, DURST AND AVANTS (2013):</head><p>ANTS AND ÁRBOLES Description: Given the success of random forest (RF)-based approaches in the BRATS 2012 challenge, we employed RFs to produce a completely automated, multi-modality brain segmentation framework. However, differences from related work include an expanded feature image set, concatenated RF modeling, and an open source implementation <ref type="bibr" target="#b48">16</ref> heavily dependent on the Advanced Normalization Tools (ANTs) 17 repository including its R packaging (ANTsR). <ref type="bibr" target="#b50">18</ref> It is the latter open source aspect of our work which significantly motivated our participation in BRATS 2013 as it provides a reproducible and publicly available framework for performing such an important task in neuroimaging <ref type="bibr" target="#b153">[121]</ref>.</p><p>Algorithm and Data: The workflow for estimating tumorbased labeling from multi-modal images involves the following steps.</p><p>1) Symmetric multivariate template construction <ref type="bibr" target="#b154">[122]</ref> using the data described in <ref type="bibr" target="#b155">[123]</ref>. • generation of single-modality MAP-MRF images using the Stage 1 RF probability images as spatial priors; • construction of the Stage 2 RF model and labelings. <ref type="bibr" target="#b48">16</ref> github.com/ntustison/BRATS2013 17 stnava.github.io/ANTs 18 stnava.github.io/ANTsR 5) Refinement of Stage 2 labelings using a heuristically-derived binary morphological processing protocol. We used the following feature images: <ref type="table">• Per modality (FLAIR, T1, T1C, T2)</ref> -First-order neighborhood statistical images: mean, variance, skewness, and entropy. Neighborhood radius . -GMM (stage 1) and MAP-MRF (stage 2) posteriors: CSF, gray matter, white matter, necrosis, edema, nonenhancing tumor and enhancing tumor (or a subset for the simulated data). -GMM (stage 1) and MAP-MRF (stage 2) connected component geometry features: distance to tumor core label, volume, volume to surface area ratio, eccentricity, and elongation. -Template-based: symmetric template difference and contralateral difference with Gaussian smoothing ( mm). • Miscellaneous: normalized Euclidean distance based on cerebral mask, log Jacobian image, and (T1C -T1) difference image. Prior cluster centers for specific tissue types learned from training data are used in the first stage to construct multiple GMM-based feature images <ref type="bibr" target="#b156">[124]</ref>. The resulting spatial priors derived from application of the RF model for the first stage were used as input to an iterative -tissue N4 Atropos MAP-MRF segmentation protocol. These are used to create modified feature images for the second stage. ANTs registration <ref type="bibr" target="#b157">[125]</ref> is also used to produce three sets of feature images: the log Jacobian image, intensity differences between each modality of each subject and the corresponding symmetric template, and contralateral differences.</p><p>All processing was performed using the computational cluster at the University of Virginia. <ref type="bibr" target="#b51">19</ref> Timing measures (single-threaded) included 1.5 h per subject for feature image creation with the bulk of time devoted to spatial normalization with the symmetric template. Model construction required 2 h with prediction taking approximately 15 min per subject. Training and Testing: Training was performed separately for both real and simulated data and high-grade versus low-grade tumor assessment resulting in four RF modeling/prediction pathways. Training was limited to the 80 evaluation datasets provided by the organizers with evaluation employing a leave-one-out strategy for each of the four groupings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ZHAO AND CORSO (2012): BRAIN TUMOR SEGMENTATION WITH MRF ON SUPERVOXELS</head><p>Algorithm and Data: For each MRI case, we first perform over-segmentation, which results in a set of supervoxels. We then solve the voxel labeling problem directly on the supervoxels constraining all voxels within one supervoxel to have the same label.</p><p>Consider a Markov random field defined over the supervoxels . A labeling assigns a label to each supervoxel P, where , necrosis, edema, non-enhancing tumor, enhancing tumor, cerebrospinal fluid and background (white matter and gray matter), respectively. The energy function</p><p>where is the set of supervoxels and is the set of adjacent supervoxels, captures the cost of a certain labeling . We define the data term as , where is the node class likelihood estimated by a Gaussian mixture model and denotes the feature of voxel , the intensities of of four channels. We define the smoothness term to capture the edge presence along the common boundary of the two supervoxels where , are two nonnegative parameter, and is the neighborhood of .</p><p>is defined as</p><p>where is a voxel, such that and are symmetric about . Finally, we solve the supervoxel labeling energy minimization problem using graph cuts <ref type="bibr" target="#b158">[126]</ref>- <ref type="bibr" target="#b160">[128]</ref>.</p><p>The computing time is about 20 min for each case with Matlab an Intel Core i7-3770K, 3.50 GHz processor and 16 GB memory system. The most time consuming part is over-segmentation and computing in (4). Because we use intensities directly as the feature, we compute the standard scores to put the data in the same scale.</p><p>Training and Testing: We made a two-fold cross-validation on high-grade and low-grade cases, respectively. We learn individual classifiers for the high-grade set and the low-grade set with the same algorithm. As most other supervised methods using intensities as the feature, the accuracy of our method depends on the standardization of intensities. Hence, our method may fail if the case has different distribution with other cases. In some cases, our method fails because the data is not good enough. For example, in some cases, extraction is not good enough to remove the whole skull (we did not try to make a better extraction), and in some other cases, we do not have the whole image on FLAIR channel. But our method also fails on some good cases.</p><p>To overcome this problem, we could make a rough segmentation first, get the normal part of the case (white matter, gray matter, CSF), and make the intensity standardization only with the normal part. We are working on such a method and may use it in BRATS 2013 if it works. ZHAO, SARIKAYA AND CORSO (2013): AUTOMATIC BRAIN TUMOR SEGMENTATION WITH MRF ON SUPERVOXELS Algorithm and Data: We normalize the data and estimate the likelihood of pixels by the registration of a 3D joint histogram. We first perform over-segmentation on each case, resulting in a set of supervoxels. We then solve the voxel labeling problem directly on the supervoxels with Markov random field. This algorithm do not need manual input.</p><p>Pre-Processing: For each channel of each MRI case, we first denoise with SUSAN <ref type="bibr" target="#b161">[129]</ref>; then we compute the standardized z-scores (zero mean and unit covariance) to put the data in the same scale, which are the feature vectors we use.</p><p>Oversegmentation of the Image With Supervoxels: In order to obtain supervoxels of MRI scan images, we use SLIC 3D <ref type="bibr" target="#b162">[130]</ref> which generates supervoxels by clustering voxels based on their color similarity and proximity in the image volume. RegionSize and regularizer, the two parameters of SLIC, are 10 and 0.1, respectively.</p><p>Segmentation With Graph Cuts on a Markov Random Field: Consider a Markov random field defined over the supervoxels with A labeling where is the set of adjacent supervoxels. We define the data term as , where is the node class likelihood estimated by histogram based method and denotes the feature of voxel . two supervoxels:</p><p>where is the neighborhood of . is defined as where is a voxel, such that and are symmetric about . Finally, we solve the labeling energy minimization problem using graph cuts <ref type="bibr" target="#b163">[131]</ref>.</p><p>In this step, the key parameters and 0.5 and 15, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Histogram Based Likelihood Estimation</head><p>Given a testing image and a labeled training image , we estimate the likelihood for each voxel with Algorithm 2.</p><p>We then integrate information from each training image as follows:</p><p>Running Time: The running time is about min for each case, where is the number of cases of training data. The most consuming part is 3D registration of histograms. This depends on the size of the histogram and the method for registration.</p><p>Training and Testing: We learned individual classifiers for each of the four sub-problems. For each sub-problem, we use a 2-fold cross validation for the parameters and in the smoothness term of MRF, however, we set to manually. We only use the training data from the BRATS challenge.</p><p>Shortcomings: The performance of the over-segmentation limits the accuracy of our method. To overcome this, we could make a voxel level labeling in the supervoxels along the boundary, after the supervoxel labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ZIKIC, GLOCKER, KONUKOGLU, SHOTTON, CRIMINISI, YE, DEMIRALP, THOMAS, DAS, JENA, AND PRICE (2012): CONTEXT-SENSITIVE CLASSIFICATION FORESTS FOR SEGMENTATION OF BRAIN TUMOR TISSUES</head><p>Description: This submission is based on a classification forest, which is used such as to produce context-sensitive predictions. The method is based on our work focusing on high-grade glioma <ref type="bibr" target="#b71">[39]</ref>, with further technical details available in <ref type="bibr" target="#b83">[51]</ref>. The context sensitivity arises from two components in the framework. The first one is that the forest does not operate only on the original input images, but also on initial patient-specific probabilities for each tissue class . These probabilities are computed at test time for each patient as the posterior probability , based on the likelihood of the multi-channel intensity given . and are estimated based on the training dataset-the likelihood by a Gaussian mixture model, and the prior as a normalized empirical histogram. While the initial probabilities often give reasonable rough estimates, they are noisy and erroneous, due to use of local intensity information only. Presenting the initial estimates to the forest as additional input has the effect of removing the noise and correcting some misclassifications. The second context-inducing component is the use of context-sensitive features for the forest (similar to <ref type="bibr" target="#b164">[132]</ref>, <ref type="bibr" target="#b165">[133]</ref>), which capture intensity characteristics around the point of interest. Due to the regularizing effect of the context-sensitive forest, we did not find it necessary to use an explicit energy-based regularization.</p><p>We use the following preprocessing. For each patient, all scans are affinely aligned to the T1 contrast scan. We perform inhomogeneity correction with <ref type="bibr" target="#b114">[82]</ref>. Instead of the standard histogram equalization, we multiply the intensities in each scan, such that the mean value equals 1000.</p><p>Our approach is fully automatic. The segmentation takes 1-2 min per scan (excluding pre-processing). The training of one tree takes ca. 20 min on a single PC. The key parameters of the method are the number of trees per forest and the maximal tree depth. We use forests with 100 trees with maximal depth of 20 for all challenge submissions (except the 2-class training data, where 40 trees per forest were used). An analysis of the parameter settings can be found in <ref type="bibr" target="#b71">[39]</ref>.</p><p>Method and parameter tuning were performed by a leaveone-out cross-validation on the initial BRATS 2-class training data. The same settings were then used for all submissions. We learn individual classifiers for the four sub-tasks (real/ high, real/low, sim/high, sim/low). Since we did not perform a cross-validation to modify any parameters for the 4-class setting, the error reported in the system for 4-class training is based on a classifier trained on all images, which explains the high score.</p><p>The largest potential for improvement seems to be to attempt to achieve better results for outlier patients with very low accuracy (cf. <ref type="bibr" target="#b83">[51]</ref>). This might be done by using more training data, or by taking into account further information, e.g., whether the scan is pre or post surgery.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Examples from the BRATS training data, with tumor regions as inferred from the annotations of individual experts (blue lines) and consensus segmentation (magenta lines). Each row shows two cases of high-grade tumor (rows 1-4), low-grade tumor (rows 5-6), or synthetic cases (last row). Images vary between axial, sagittal, and transversal views, showing for each case: FLAIR with outlines of the whole tumor region (left); T2 with outlines of the core region (center); T1c with outlines of the active tumor region if present (right). Best viewed when zooming into the electronic version of the manuscript.The appropriate intensity threshold was determined visually on a case-by-case basis [Fig. 3(C)]. 4) The "necrotic (or fluid-filled) core" was defined as the tortuous, low intensity necrotic structures within the enhancing rim visible in T1c. The same label was also used for the very rare instances of hemorrhages in the BRATS data [Fig. 3(C)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Manual annotation through expert raters. Shown are image patches with the tumor structures that are annotated in the different modalities (top left) and the final labels for the whole dataset (right). Image patches show from left to right: the whole tumor visible in FLAIR (A), the tumor core visible in T2 (B), the enhancing tumor structures visible in T1c (blue), surrounding the cystic/necrotic components of the core (green) (C). Segmentations are combined to generate the final labels of the tumor structures (D): edema (yellow), non-enhancing solid core (red), necrotic/cystic core (green), enhancing core(blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Regions used for calculating Dice score, sensitivity, specificity, and robust Hausdorff score. Region is the true lesion area (outline blue), is the remaining normal area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5</head><label>5</label><figDesc>Fig. 5. Dice scores of inter-rater variation (top left), and variation around the "fused" consensus label (top right). Shown are results for the "whole" tumor region (including all four tumor structures), the tumor "core" region (including enhancing, non-enhancing core, and necrotic structures), and the "active" tumor region (that features the T1c enhancing structures). Black boxplots show training data (30 cases); gray boxes show results for the test data (15 cases). Scores for "active" tumor region are calculated for high-grade cases only (15/11 cases). Boxes report quartiles including the median; whiskers and dots indicate outliers (some of which are below 0.5 Dice); and triangles report mean values. Table at the bottom shows quantitative values for the training and test datasets, including scores for low-and high-grade cases (LG/HG) separately; here "std" denotes standard deviation, and "mad" denotes median absolute deviance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>On-site test results of the 2012 challenge (top left and right) and the 2013 challenge (bottom left), reporting average Dice scores. Test data for 2012 included both real and synthetic images, with a mix of low-and high-grade cases (LG/HG): 11/4 HG/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 8 .</head><label>8</label><figDesc>Dispersion of Dice and Hausdorff scores from the "off-site" test for the individual algorithms (color coded), and various fused algorithmic segmentations (gray), shown together with the expert results taken fromFig. 5 (also shown in gray). Boxplots show quartile ranges of the scores on the test datasets; whiskers and dots indicate outliers. Black squares indicate the mean score (for Dice also shown in the table of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 9 .</head><label>9</label><figDesc>Examples from the test data set, with consensus expert annotations (yellow) and consensus of four algorithmic labels overlaid (magenta). Blue lines indicate the individual segmentations of four different algorithms (Menze (D), Subbanna, Zhao (I), Hamamci). Each row shows two cases of high-grade tumor (rows 1-5) and low-grade tumor (rows 6-7). Three images are shown for each case: FLAIR (left), T2 (center), and T1c (right). Annotated are outlines of the whole tumor (shown in FLAIR), of the core region (shown in T2), and of active tumor region (shown in T1c, if applicable). Views vary between patients with axial, sagittal and transversal intersections with the tumor center. Note that clinical low-grade cases show image changes that have been interpreted by some of the experts as enhancements in T1c.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>different algorithms, either by majority vote or by other fusion strategies. CONTRIBUTIONS B. H. Menze, A. Jakab, S. Bauer, M. Reyes, M. Prastawa, and K. Van Leemput organized BRATS 2012. B. H. Menze, M. Reyes, J. Kalpathy-Cramer, J. Kirby, and K. Farahani organized BRATS 2013. A. Jakab and B. H. Menze defined the annotation protocol. A. Jakab, Y. Burren, N. Porz, J. Slotboom, R. Wiest, L. Lanczi, and M.-A. Weber acquired and annotated the clinical images. M. Prastawa generated the synthetic images. M. Prastawa and S. Bauer pre-processed the images. M. Prastawa implemented the evaluation scripts. S. Bauer, M. Reyes, and M. Prastawa adapted and maintained the online evaluation tools. All other authors contributed results of their tumor segmentation algorithms as indicated in the Appendix. B. H. Menze analyzed the data. B. H. Menze and K. Van Leemput wrote the manuscript. B. H. Menze wrote the first draft.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 .</head><label>11</label><figDesc>Generic flow diagram of the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 .</head><label>12</label><figDesc>Left: Training the HMM model. Center: MapReduce model for HMMbased brain tumor segmentation. Right: Applying the HMM model for segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2 )</head><label>2</label><figDesc>Image preprocessing: • Windowing intensities (quantiles [0.01, 0.99]); • N4 bias correction [103]; • Rescaling intensity range to [0, 1]. 3) Stage 1 (GMM) processing: • generation of feature images; • construction of the Stage 1 RF model and probability images. 4) Stage 2 processing:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">challenge.kitware.com/midas/folder/102, www.virtualskeleton.ch/ 2 Available online: www.braintumorsegmentation.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">www.nitrc.org/projects/tumorsim</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">www.slicer.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">www.midasplatform.org<ref type="bibr" target="#b40">8</ref> github.com/InsightSoftwareConsortium/covalic</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">BRATS 2013: hal.inria.fr/hal-00912934; BRATS 2012: hal.inria.fr/hal-00912935</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This research was supported by the NIH NCRR (P41-RR14075), the NIH NIBIB (R01EB013565), the Academy of Finland (133611), TEKES (ComBrain), the Lundbeck Foundation (R141-2013-13117), the Swiss Cancer League, the Swiss Institute for Computer Assisted Surgery (SICAS), the NIH NIBIB NAMIC (U54-EB005149), the NIH NCRR NAC (P41-RR13218), the NIH NIBIB NAC (P41-EB-015902), the NIH NCI (R15CA115464), the European Research Council through the ERC Advanced Grant </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">European Union (Rudolf Mössbauer Tenure-Track Professorship to BHM)</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">European Union (Rudolf Mössbauer Tenure-Track Professor- ship to BHM).</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Menze is with the Institute for Advanced Study and</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename><forename type="middle">B H</forename></persName>
		</author>
		<imprint>
			<pubPlace>Munich, Germany; ETH, Zürich, Switzerland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Technische Universität München ; Computer Vision Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">*B. H. Menze is with the Institute for Advanced Study and Department of Computer Science, Technische Universität München, Munich, Germany, and with the Computer Vision Laboratory, ETH, Zürich, Switzerland, and with the</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Asclepios Project</title>
		<imprint/>
		<respStmt>
			<orgName>Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Asclepios Project, Inria, Sophia-Antipolis, France, and also with the Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Tech- nology, Cambridge, MA 02139 USA.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bauer is with the Institute for Surgical Technology and Biomechanics</title>
		<imprint>
			<pubPlace>Debrecen, Hungary S; Switzerland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>A. Jakab is with the Computer Vision Laboratory, ETH, Zürich, Switzerland, and also with the University of Debrecen ; University of Bern ; Support Center for Advanced Neuroimaging (SCAN), Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">A. Jakab is with the Computer Vision Laboratory, ETH, Zürich, Switzerland, and also with the University of Debrecen, Debrecen, Hungary S. Bauer is with the Institute for Surgical Technology and Biomechanics, University of Bern, Switzerland, and also with the Support Center for Advanced Neuroimaging (SCAN), Institute for Diagnostic and Interventional Neuroradi- ology, Inselspital, Bern University Hospital, Switzerland.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cramer is with the Department of Radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kalpathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Massachusetts General Hospital</title>
		<imprint/>
	</monogr>
	<note>Harvard Medical School</note>
	<note type="raw_reference">J. Kalpathy-Cramer is with the Department of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston MA, USA.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Kirby are with the Cancer Imaging Program, National Cancer Institute, National Institutes of Health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<pubPlace>Bethesda MD, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">K. Farahani and J. Kirby are with the Cancer Imaging Program, National Cancer Institute, National Institutes of Health, Bethesda MD, USA.</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wiest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Porz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Slotboom are with the Support Center for Advanced Neuroimaging (SCAN)</title>
		<meeting><address><addrLine>Debrecen; Boston MA, USA</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, Switzerland. L. Lanczi is with University of Debrecen</orgName>
		</respStmt>
	</monogr>
	<note>Harvard Medical School</note>
	<note type="raw_reference">R. Wiest, Y. Burren, N. Porz and J. Slotboom are with the Support Center for Advanced Neuroimaging (SCAN), Institute for Diagnostic and Interventional Neuroradiology, Inselspital, Bern University Hospital, Switzerland. L. Lanczi is with University of Debrecen, Debrecen, Hungary. E. Gerstner is with the Department of Neuro-oncology, Massachusetts General Hosptial, Harvard Medical School, Boston MA, USA.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">B. Glocker is with BioMedIA Group</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">B. Glocker is with BioMedIA Group, Imperial College, London, U.K.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Avants is with the Penn Image Computing and Science Lab, Department of Radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ayache, N. Cordier, H. Delingette, and E. Geremia are with the Asclepios Project, INRIA</title>
		<meeting><address><addrLine>University of Pennsylvania, Philadelphia PA, USA; Sophia-Antipolis, France</addrLine></address></meeting>
		<imprint/>
		<respStmt>
			<orgName>McGill University, Canada B. B</orgName>
		</respStmt>
	</monogr>
	<note>Subbanna are with the Centre for Intelligent Machines</note>
	<note type="raw_reference">T. Arbel and N. K. Subbanna are with the Centre for Intelligent Machines, McGill University, Canada B. B. Avants is with the Penn Image Computing and Science Lab, Depart- ment of Radiology, University of Pennsylvania, Philadelphia PA, USA. N. Ayache, N. Cordier, H. Delingette, and E. Geremia are with the Asclepios Project, INRIA, Sophia-Antipolis, France.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Taylor are with the INFOTECH Soft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Buendia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename></persName>
		</author>
		<imprint>
			<pubPlace>Inc., Miami FL, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">P. Buendia, M. Ryan, and T. J. Taylor are with the INFOTECH Soft, Inc., Miami FL, USA.</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Collins is with the McConnell Brain Imaging Centre</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename></persName>
		</author>
		<imprint/>
		<respStmt>
			<orgName>McGill University, Canada</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">D. L. Collins is with the McConnell Brain Imaging Centre, McGill Univer- sity, Canada.</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sarikaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science and Engineering</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">J. J. Corso, D. Sarikaya, and L. Zhao are with the Computer Science and Engineering, SUNY, Buffalo NY, USA.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Zikic are with Microsoft Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<pubPlace>Cambridge, U.K</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Criminisi, J. Shotton, and D. Zikic are with Microsoft Research, Cam- bridge, U.K.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Thomas are with the Cambridge University Hospitals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint>
			<pubPlace>Cambridge, U.K</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">T. Das, R. Jena, S. J. Price, and O. M. Thomas are with the Cambridge University Hospitals, Cambridge, U.K.</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vasseur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dojat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Forbes are with the INRIA</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">S. Doyle, F. Vasseur, M. Dojat, and F. Forbes are with the INRIA</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rhône-Alpes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INSERM</title>
		<imprint>
			<biblScope unit="volume">836</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">Rhône-Alpes, Grenoble, France, and also with the INSERM, U836, Grenoble, France.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Wintermark are with the Department of Radiology and Medical Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Durst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Tustison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<pubPlace>University of Virginia, Charlottesville VA USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">C. R. Durst, N. J. Tustison, and M. Wintermark are with the Department of Radiology and Medical Imaging, University of Virginia, Charlottesville VA USA.</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Silva are with the Department of Electronics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Festa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<pubPlace>University Minho, Portugal</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">J. Festa, S. Pereira, and C. A. Silva are with the Department of Electronics, University Minho, Portugal.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Lashkari are with the Computer Science and Artificial Intelligence Laboratory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<pubPlace>Massachusetts Institute of Technology, Cambridge MA USA</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">P. Golland and D. Lashkari are with the Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge MA USA.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Zhao are with Department of Radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<imprint>
			<pubPlace>New York, NY USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">X. Guo, L. Schwartz, B. Zhao are with Department of Radiology, Columbia University, New York, NY USA.</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unal are with the Faculty of Engineering and Natural Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamamci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<pubPlace>Istanbul, Turkey</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Sabanci University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">A. Hamamci and G. Unal are with the Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey.</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Reza are with the Vision Lab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Iftekharuddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint>
			<pubPlace>Norfolk, VA USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Electrical and Computer Engineering, Old Dominion University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">K. M. Iftekharuddin and S. M. S. Reza are with the Vision Lab, Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA USA.</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">John is with INFOTECH Soft, Inc</title>
		<imprint/>
		<respStmt>
			<orgName>Department of Electrical and Computer Engineering, University of Miami</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">N. M. John is with INFOTECH Soft, Inc., Miami, FL USA, and also with the Department of Electrical and Computer Engineering, University of Miami, Coral Gables FL USA.</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">E. Konukoglu is with Athinoula A. Martinos Center for Biomedical</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">E. Konukoglu is with Athinoula A. Martinos Center for Biomedical</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Massachusetts General Hospital and Harvard Medical School</title>
	</analytic>
	<monogr>
		<title level="j">Imaging</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">Imaging, Massachusetts General Hospital and Harvard Medical School, Boston MA USA.</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Sousa are with the Life and Health Science Research Institute (ICVS), School of Health Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Mariz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename></persName>
		</author>
		<imprint>
			<pubPlace>Braga; Braga/Guimaraes, Portugal</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Minho</orgName>
		</respStmt>
	</monogr>
	<note>Portugal, and also with the ICVS/3B&apos;s-PT Government Associate Laboratory</note>
	<note type="raw_reference">J. A. Mariz and N. Sousa are with the Life and Health Science Research Institute (ICVS), School of Health Sciences, University of Minho, Braga, Por- tugal, and also with the ICVS/3B&apos;s-PT Government Associate Laboratory, Braga/Guimaraes, Portugal.</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Reyes are with the Institute for Surgical Technology and Biomechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<biblScope unit="page">3014</biblScope>
			<pubPlace>Bern, Switzerland</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Bern</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">R. Meier and M. Reyes are with the Institute for Surgical Technology and Biomechanics, University of Bern, 3014 Bern, Switzerland.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canada</forename></persName>
		</author>
		<imprint>
			<pubPlace>Beer-Sheva, Israel; Sutton, U.K</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering Department, Ben-Gurion University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">Canada. and also with the Electrical and Computer Engineering Department, Ben-Gurion University, Beer-Sheva, Israel. H.-C. Shin is from Sutton, U.K.</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Szekely is with the Computer Vision Laboratory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint>
			<pubPlace>ETH, Zürich, Switzerland</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">G. Szekely is with the Computer Vision Laboratory, ETH, Zürich, Switzer- land.</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename></persName>
		</author>
		<imprint>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Weber is with Diagnostic and Interventional Radiology, University Hospital</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">M.-A. Weber is with Diagnostic and Interventional Radiology, University Hospital, Heidelberg, Germany.</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Ye is with the Electrical and</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename></persName>
		</author>
		<imprint>
			<pubPlace>USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Computer Engineering Department, Purdue University</orgName>
		</respStmt>
	</monogr>
	<note type="raw_reference">D. H. Ye is with the Electrical and Computer Engineering Department, Purdue University, USA.</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prastawa is with the GE Global Research</title>
		<imprint/>
	</monogr>
	<note type="raw_reference">M. Prastawa is with the GE Global Research, Niskayuna NY, USA.</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Leemput is with the Department of Radiology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Massachusetts General Hospital</title>
		<imprint/>
		<respStmt>
			<orgName>Technical University of Denmark, Denmark, and also with Aalto University</orgName>
		</respStmt>
	</monogr>
	<note>Harvard Medical School</note>
	<note type="raw_reference">K. Van Leemput is with the Department of Radiology, Massachusetts Gen- eral Hospital, Harvard Medical School, Boston, MA 02129 USA, and with the Technical University of Denmark, Denmark, and also with Aalto University, Finland. REFERENCES</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Progenitor cells and glioma formation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Neurol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="683" to="688" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. C. Holland, &quot;Progenitor cells and glioma formation,&quot; Curr. Opin. Neurol., vol. 14, pp. 683-688, 2001.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Population-based studies on incidence, survival rates, and genetic alterations in astrocytic and oligodendroglial gliomas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ohgaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kleihues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neuropathol. Exp. Neurol</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="479" to="489" />
			<date type="published" when="2005-06" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. Ohgaki and P. Kleihues, &quot;Population-based studies on incidence, survival rates, and genetic alterations in astrocytic and oligodendroglial gliomas,&quot; J. Neuropathol. Exp. Neurol., vol. 64, no. 6, pp. 479-489, Jun. 2005.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ohgaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">D</forename><surname>Wiestler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Cavanee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WHO classification of tumours of the central nervous system WHO/IARC</title>
		<meeting><address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. H. Louis, H. Ohgaki, O. D. Wiestler, and W. K. Cavanee, WHO classification of tumours of the central nervous system WHO/IARC., Lyon, France, Tech. Rep., 2007.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">New response evaluation criteria in solid tumours: Revised RECIST guideline (version 1.1)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eisenhauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Cancer</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="247" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. Eisenhauer et al., &quot;New response evaluation criteria in solid tu- mours: Revised RECIST guideline (version 1.1),&quot; Eur. J. Cancer, vol. 45, no. 2, pp. 228-247, 2009.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Updated response assessment criteria for high-grade gliomas: Response assessment in neuro-oncology working group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Clin. Oncol</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1963" to="1972" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Y. Wen et al., &quot;Updated response assessment criteria for high-grade gliomas: Response assessment in neuro-oncology working group,&quot; J. Clin. Oncol., vol. 28, pp. 1963-1972, 2010.</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Glioma dynamics and computational models: A review of segmentation, registration, and in silico growth algorithms and their clinical applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Angelini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Clatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mandonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Capelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Duffau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Med. Imag. Rev</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="262" to="276" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. D. Angelini, O. Clatz, E. Mandonnet, E. Konukoglu, L. Capelle, and H. Duffau, &quot;Glioma dynamics and computational models: A re- view of segmentation, registration, and in silico growth algorithms and their clinical applications,&quot; Curr. Med. Imag. Rev., vol. 3, pp. 262-276, 2007.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A survey of MRI-based medical image analysis for brain tumor studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wiest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Med. Biol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="97" to="129" />
			<date type="published" when="2013-07" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer, R. Wiest, L.-P. Nolte, and M. Reyes, &quot;A survey of MRI-based medical image analysis for brain tumor studies,&quot; Phys. Med. Biol., vol. 58, no. 13, pp. R97-R129, Jul. 2013.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Segmentation of meningiomas and low grade gliomas in MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Kaus et al., &quot;Segmentation of meningiomas and low grade gliomas in MRI,&quot; in Proc. MICCAI, 1999, pp. 1-10.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automatic segmentation of non-enhancing brain tumors in magnetic resonance images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Fletcher-Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Goldgof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Murtagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Med</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="43" to="63" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. M. Fletcher-Heath, L. O. Hall, D. B. Goldgof, and F. R. Murtagh, &quot;Automatic segmentation of non-enhancing brain tumors in magnetic resonance images.,&quot; Artif. Intell. Med., vol. 21, no. 1-3, pp. 43-63, 2001.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic MRI meningioma segmentation using estimation maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-J</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. IEEE Eng. Med. Biol. Soc</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3074" to="3077" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y.-F. Tsai, I.-J. Chiang, Y.-C. Lee, C.-C. Liao, and K.-L. Wang, &quot;Auto- matic MRI meningioma segmentation using estimation maximization,&quot; Proc. IEEE Eng. Med. Biol. Soc., vol. 3, pp. 3074-3077, 2005.</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Monitoring slowly evolving tumors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISBI</title>
		<meeting>ISBI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. Konukoglu et al., &quot;Monitoring slowly evolving tumors,&quot; in Proc. ISBI, 2008, pp. 1-4.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dense deformation field estimation for atlas-based segmentation of pathological MR brain images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Cuadra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Craene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Duay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Macq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pollo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="66" to="75" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. B. Cuadra, M. D. Craene, V. Duay, B. Macq, C. Pollo, and J.-P. Thiran, &quot;Dense deformation field estimation for atlas-based segmen- tation of pathological MR brain images,&quot; Comput. Methods Programs Biomed., vol. 84, pp. 66-75, 2006.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Automatic segmentation, internal classification, and follow-up of optic pathway gliomas in MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weizman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="188" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. Weizman et al., &quot;Automatic segmentation, internal classification, and follow-up of optic pathway gliomas in MRI,&quot; Med. Image Anal., vol. 16, no. 1, pp. 177-188, 2012.</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">3D segmentation in the clinic: A grand challenge II: MS lesion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Styner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIDAS J</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Styner et al., &quot;3D segmentation in the clinic: A grand challenge II: MS lesion segmentation,&quot; MIDAS J., pp. 1-5, 2008.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Automated model-based bias field correction of MR images of the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="885" to="896" />
			<date type="published" when="1999-10" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. Van Leemput, F. Maes, D. Vandermeulen, and P. Suetens, &quot;Auto- mated model-based bias field correction of MR images of the brain,&quot; IEEE Trans. Med. Imag., vol. 18, no. 10, pp. 885-896, Oct. 1999.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automated segmentation of MR images of brain tumors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Kaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nabavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Jolesz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="586" to="591" />
			<date type="published" when="2001-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. R. Kaus, S. K. Warfield, A. Nabavi, P. M. Black, F. A. Jolesz, and R. Kikinis, &quot;Automated segmentation of MR images of brain tumors,&quot; Radiology, vol. 218, no. 2, pp. 586-591, Feb. 2001.</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A brain tumor segmentation framework based on outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prastawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="275" to="283" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Prastawa, E. Bullitt, S. Ho, and G. Gerig, &quot;A brain tumor segmen- tation framework based on outlier detection,&quot; Med. Image Anal., vol. 8, pp. 275-283, 2004.</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A unifying approach to registration, segmentation, and intensity correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Pohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Levitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Shenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. M. Pohl, J. Fisher, J. J. Levitt, M. E. Shenton, R. Kikinis, W. E. L. Grimson, and W. M. Wells, &quot;A unifying approach to registration, segmentation, and intensity correction,&quot; in Proc. MICCAI, 2005, pp. 310-318.</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Comparative validation of graphical models for learning tumor segmentations from noisy manual annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">O</forename><surname>Kaster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-MCV</title>
		<meeting>MICCAI-MCV</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="raw_reference">F. O. Kaster, B. H. Menze, M.-A. Weber, and F. A. Hamprecht, &quot;Com- parative validation of graphical models for learning tumor segmenta- tions from noisy manual annotations,&quot; in Proc. MICCAI-MCV, 2010.</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Whole brain segmentation: Automated labeling of neuroanatomical structures in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="355" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Fischl et al., &quot;Whole brain segmentation: Automated labeling of neuroanatomical structures in the human brain,&quot; Neuron., vol. 33, no. 3, pp. 341-355, 2002.</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unified segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Ashburner and K. J. Friston, &quot;Unified segmentation,&quot; Neuroimage, vol. 26, no. 3, pp. 839-851, 2005.</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">ORBIT: A multiresolution framework for deformable registration of brain tumor images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Zacharaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1003" to="1017" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. I. Zacharaki, D. Shen, and C. Davatzikos, &quot;ORBIT: A multireso- lution framework for deformable registration of brain tumor images,&quot; IEEE Trans. Med. Imag., vol. 27, no. 8, pp. 1003-1017, Aug. 2008.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Atlas-based segmentation of pathological brain MR images using a model of lesion growth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bach Cuadra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pollo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bardera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Cuisenaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Thiran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1301" to="1314" />
			<date type="published" when="2004-10" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Bach Cuadra, C. Pollo, A. Bardera, O. Cuisenaire, and J. P. Thiran, &quot;Atlas-based segmentation of pathological brain MR images using a model of lesion growth,&quot; IEEE Trans. Med. Imag., vol. 23, no. 10, pp. 1301-1314, Oct. 2004.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Recognizing deviations from normalcy for brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grimson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kikinis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI 2002</title>
		<meeting>MICCAI 2002</meeting>
		<imprint>
			<date type="published" when="2002-09" />
			<biblScope unit="volume">2488</biblScope>
			<biblScope unit="page" from="388" to="395" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Gering, W. Grimson, and R. Kikinis, &quot;Recognizing deviations from normalcy for brain tumor segmentation,&quot; Proc. MICCAI 2002, vol. 2488, pp. 388-395, Sept. 2002.</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automated segmentation of multiple sclerosis lesions by model outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Colchester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Suetens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="677" to="688" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. Van Leemput, F. Maes, D. Vandermeulen, A. Colchester, and P. Suetens, &quot;Automated segmentation of multiple sclerosis lesions by model outlier detection,&quot; IEEE Trans. Med. Imag., vol. 20, pp. 677-688, 2001.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Lesion identification using unified segmentation-normalisation models and fuzzy clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Seghier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramlackhansingh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Crinion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Leff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1253" to="1266" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. L. Seghier, A. Ramlackhansingh, J. Crinion, A. P. Leff, and C. J. Price, &quot;Lesion identification using unified segmentation-normalisa- tion models and fuzzy clustering,&quot; Neuroimage, vol. 41, no. 4, pp. 1253-1266, 2008.</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Model-based brain and tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="528" to="531" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Moon, E. Bullitt, K. Van Leemput, and G. Gerig, &quot;Model-based brain and tumor segmentation,&quot; in Proc. ICPR, 2002, pp. 528-531.</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Automatic brain tumor segmentation by subject specific modification of atlas priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prastawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1341" to="1348" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Prastawa, E. Bullitt, N. Moon, K. V. Leemput, and G. Gerig, &quot;Au- tomatic brain tumor segmentation by subject specific modification of atlas priors,&quot; Acad. Radiol., vol. 10, pp. 1341-1348, 2003.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">GLISTR: Glioma image segmentation and registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gooya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1941" to="1954" />
			<date type="published" when="2012-10" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Gooya et al., &quot;GLISTR: Glioma image segmentation and registra- tion,&quot; IEEE Trans. Med. Imag., vol. 31, no. 10, pp. 1941-1954, Oct. 2012.</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Joint tumor segmentation and dense deformable registration of brain MR images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parisot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Duffau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chemouny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="651" to="658" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Parisot, H. Duffau, S. Chemouny, and N. Paragios, &quot;Joint tumor segmentation and dense deformable registration of brain MR images,&quot; in Proc. MICCAI, 2012, pp. 651-658.</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deformable registration of glioma images using EM algorithm and diffusion reaction modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gooya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Biros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="375" to="390" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Gooya, G. Biros, and C. Davatzikos, &quot;Deformable registration of glioma images using EM algorithm and diffusion reaction modeling,&quot; IEEE Trans. Med. Imag., vol. 30, no. 2, pp. 375-390, Feb. 2011.</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">3D variational brain tumor segmentation using a high dimensional feature set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cobzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Birkbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jagersand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Murtha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Cobzas, N. Birkbeck, M. Schmidt, M. Jagersand, and A. Murtha, &quot;3D variational brain tumor segmentation using a high dimensional feature set,&quot; in Proc. ICCV, 2007, pp. 1-8.</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Interactive, GPU-based level sets for 3D brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lefohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Whitaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="564" to="572" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Lefohn, J. Cates, and R. Whitaker, &quot;Interactive, GPU-based level sets for 3D brain tumor segmentation,&quot; in Proc. MICCAI, 2003, pp. 564-572.</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Multiparametric tissue characterization of brain neoplasms and their recurrence using pattern classification of MR images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="966" to="77" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Verma et al., &quot;Multiparametric tissue characterization of brain neo- plasms and their recurrence using pattern classification of MR images,&quot; Acad. Radiol., vol. 15, no. 8, pp. 966-77, Aug. 2008.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Level-set evolution with region competition: Automatic 3D segmentation of brain tumors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="532" to="535" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Ho, E. Bullitt, and G. Gerig, &quot;Level-set evolution with region com- petition: Automatic 3D segmentation of brain tumors,&quot; in Proc. ICPR, 2002, pp. 532-535.</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Semi-supervised tumor detection in magnetic resonance spectroscopic images using discriminative random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gorlitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Kelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. DAGM</title>
		<meeting>DAGM</meeting>
		<imprint>
			<publisher>ser. LNCS</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="224" to="233" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. Gorlitz, B. H. Menze, M.-A. Weber, B. M. Kelm, and F. A. Ham- precht, &quot;Semi-supervised tumor detection in magnetic resonance spec- troscopic images using discriminative random fields,&quot; in Proc. DAGM, 2007, pp. 224-233, ser. LNCS.</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Segmenting brain tumors using pseudo conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Murtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Greiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="359" to="366" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Lee, S. Wang, A. Murtha, and R. Greiner, &quot;Segmenting brain tumors using pseudo conditional random fields,&quot; in Proc. MICCAI, 2008, pp. 359-366.</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A discriminative model-constrained graph cuts approach to fully automated pediatric brain tumor segmentation in 3D MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hornegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">5241</biblScope>
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Wels, G. Carneiro, A. Aplas, M. Huber, J. Hornegger, and D. Co- maniciu, &quot;A discriminative model-constrained graph cuts approach to fully automated pediatric brain tumor segmentation in 3D MRI,&quot; in Proc. MICCAI, 2008, pp. 67-75, LNCS 5241.</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Decision forests for tissue-specific segmentation of high-grade gliomas in multi-channel MR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Zikic et al., &quot;Decision forests for tissue-specific segmentation of high-grade gliomas in multi-channel MR,&quot; in Proc. MICCAI, 2012.</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Spatial decision forests for MS lesion segmentation in multichannel MR images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geremia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Clatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. Geremia, B. H. Menze, O. Clatz, E. Konukoglu, A. Criminisi, and N. Ayache, &quot;Spatial decision forests for MS lesion segmentation in multi- channel MR images,&quot; in Proc. MICCAI, 2010.</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Spatial decision forests for MS lesion segmentation in multi-channel magnetic resonance images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geremia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Clatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="378" to="390" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. Geremia, O. Clatz, B. H. Menze, E. Konukoglu, A. Criminisi, and N. Ayache, &quot;Spatial decision forests for MS lesion segmentation in multi-channel magnetic resonance images,&quot; Neuroimage, vol. 57, pp. 378-390, 2011.</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Spatially adaptive random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geremia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Symp. Biomed. Imag</title>
		<meeting>IEEE Int. Symp. Biomed. Imag</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1344" to="1347" />
		</imprint>
	</monogr>
	<note type="raw_reference">E. Geremia, B. H. Menze, and N. Ayache, &quot;Spatially adaptive random forests,&quot; in Proc. IEEE Int. Symp. Biomed. Imag., 2013, pp. 1344-1347.</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="354" to="361" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer, L.-P. Nolte, and M. Reyes, &quot;Fully automatic segmentation of brain tumor images using support vector machine classification in com- bination with hierarchical conditional random field regularization,&quot; in Proc. MICCAI, 2011, pp. 354-361.</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Brain tumor detection and segmentation in a conditional random fields framework with pixelpairwise affinity and superpixel-level features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="raw_reference">W. Wu, A. Y. Chen, L. Zhao, and J. J. Corso, &quot;Brain tumor detection and segmentation in a conditional random fields framework with pixel- pairwise affinity and superpixel-level features,&quot; Int. J. Comput. Assist. Radiol. Surg., pp. 1-13, 2013.</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Cortes and V. Vapnik, &quot;Support-vector networks,&quot; Mach. Learn., vol. 20, no. 3, pp. 273-297, 1995.</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Decision Forests for Computer Vision and Medical Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">A. Criminisi and J. Shotton, Decision Forests for Computer Vision and Medical Image Analysis. Heidelberg, Germany: Springer, 2013.</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Is synthesizing MRI contrast useful for inter-modality analysis?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="631" to="638" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. E. Iglesias, E. Konukoglu, D. Zikic, B. Glocker, K. Van Leemput, and B. Fischl, &quot;Is synthesizing MRI contrast useful for inter-modality analysis?,&quot; in Proc. MICCAI, 2013, pp. 631-638.</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">A compressed sensing approach for MR tissue contrast synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Prince</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IPMI</title>
		<meeting>IPMI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="371" to="383" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Roy, A. Carass, and J. Prince, &quot;A compressed sensing approach for MR tissue contrast synthesis,&quot; in Proc. IPMI, 2011, pp. 371-383.</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Longitudinal intensity normalization in the presence of multiple sclerosis lesions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ISBI</title>
		<meeting>ISBI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1384" to="1387" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Roy et al., &quot;Longitudinal intensity normalization in the presence of multiple sclerosis lesions,&quot; in Proc. ISBI, 2013, pp. 1384-1387.</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Segmenting glioma in multi-modal images using a generative model for brain lesion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-BRATS</title>
		<meeting>MICCAI-BRATS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. H. Menze, K. Van Leemput, D. Lashkari, M.-A. Weber, N. Ayache, and P. Golland, &quot;Segmenting glioma in multi-modal images using a generative model for brain lesion segmentation,&quot; in Proc. MICCAI- BRATS, 2012, pp. 1-8.</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Context-sensitive classification forests for segmentation of brain tumor tissues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-BRATS</title>
		<meeting>MICCAI-BRATS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="22" to="30" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Zikic et al., &quot;Context-sensitive classification forests for segmenta- tion of brain tumor tissues,&quot; in Proc. MICCAI-BRATS, 2012, pp. 22-30.</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Enforcing monotonous shape growth or shrinkage in video segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Charpiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Br. Mach. Vis. Conf</title>
		<meeting>Br. Mach. Vis. Conf</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Tarabalka, G. Charpiat, L. Brucker, and B. H. Menze, &quot;Enforcing monotonous shape growth or shrinkage in video segmentation,&quot; in Proc. Br. Mach. Vis. Conf., 2013.</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Spatio-temporal video segmentation with shape growth or shrinkage constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tarabalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Charpiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Brucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3829" to="3840" />
			<date type="published" when="2014-09" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Tarabalka, G. Charpiat, L. Brucker, and B. H. Menze, &quot;Spatio-tem- poral video segmentation with shape growth or shrinkage constraint,&quot; IEEE Trans. Image Process., vol. 23, no. 9, pp. 3829-3840, Sep. 2014.</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Integrated spatio-temporal segmentation of longitudinal brain tumor imaging studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tessier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Krieter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-MCV</title>
		<meeting>MICCAI-MCV</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="122" to="130" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer, J. Tessier, O. Krieter, L. Nolte, and M. Reyes, &quot;Integrated spatio-temporal segmentation of longitudinal brain tumor imaging studies,&quot; in Proc. MICCAI-MCV, 2013, pp. 122-130.</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Joint segmentation via patient-specific latent anatomy model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riklin-Raviv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-PMMIA</title>
		<meeting>MICCAI-PMMIA</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="244" to="255" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Riklin-Raviv et al., &quot;Joint segmentation via patient-specific latent anatomy model,&quot; in Proc. MICCAI-PMMIA, 2009, pp. 244-255.</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Segmentation of image ensembles via latent atlases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Riklin-Raviv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Van Leemput</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Golland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="654" to="665" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Riklin-Raviv, K. Van Leemput, B. H. Menze, W. M. Wells, 3rd, and P. Golland, &quot;Segmentation of image ensembles via latent atlases,&quot; Med. Image Anal., vol. 14, pp. 654-665, 2010.</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Increased discrimination in level set methods with embedded conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cobzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit</meeting>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="328" to="335" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Cobzas and M. Schmidt, &quot;Increased discrimination in level set methods with embedded conditional random fields,&quot; in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2009, pp. 328-335.</note>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Efficient multilevel brain tumor segmentation with integrated Bayesian model classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="629" to="640" />
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. J. Corso et al., &quot;Efficient multilevel brain tumor segmentation with integrated Bayesian model classification,&quot; IEEE Trans. Med. Imag., vol. 27, no. 5, pp. 629-640, May 2008.</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Instrumentation bias in the use and evaluation of scientific software: Recommendations for reproducible practices in the computational sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Tustison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front. Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">162</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. J. Tustison et al., &quot;Instrumentation bias in the use and evaluation of scientific software: Recommendations for reproducible practices in the computational sciences,&quot; Front. Neurosci. vol. 7, p. 162, 2013.</note>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Online resource for validation of brain segmentation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Shattuck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Narr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Toga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="431" to="439" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. W. Shattuck, G. Prasad, M. Mirza, K. L. Narr, and A. W. Toga, &quot;Online resource for validation of brain segmentation methods,&quot; Neu- roimage, vol. 45, no. 2, pp. 431-439, 2009.</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">3D segmentation in the clinic: A grand challenge II-coronary artery tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Metz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insight J</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. Metz et al., &quot;3D segmentation in the clinic: A grand challenge II-coronary artery tracking,&quot; Insight J., vol. 1, no. 5, p. 6, 2008.</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Standardized evaluation methodology and reference database for evaluating coronary artery centerline extraction algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schaap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="701" to="714" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Schaap et al., &quot;Standardized evaluation methodology and refer- ence database for evaluating coronary artery centerline extraction al- gorithms,&quot; Med. Image Anal., vol. 13, no. 5, pp. 701-714, 2009.</note>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Evaluation framework for carotid bifurcation lumen segmentation and stenosis grading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hameeteman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="488" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. Hameeteman et al., &quot;Evaluation framework for carotid bifurcation lumen segmentation and stenosis grading,&quot; Med. Image Anal., vol. 15, no. 4, pp. 477-488, 2011.</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Comparison and evaluation of methods for liver segmentation from CT datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heimann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1251" to="1265" />
			<date type="published" when="2009-08" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Heimann et al., &quot;Comparison and evaluation of methods for liver segmentation from CT datasets,&quot; IEEE Trans. Med. Imag., vol. 28, no. 8, pp. 1251-1265, Aug. 2009.</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">3D segmentation in the clinic: A grand challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heimann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Styner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7" to="15" />
		</imprint>
	</monogr>
	<note>3D Segmentation Clinic: A Grand Challenge</note>
	<note type="raw_reference">B. Van Ginneken, T. Heimann, and M. Styner, &quot;3D segmentation in the clinic: A grand challenge,&quot; 3D Segmentation Clinic: A Grand Chal- lenge, pp. 7-15, 2007.</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Retinopathy online challenge: Automatic detection of microaneurysms in digital color fundus photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="195" />
			<date type="published" when="2010-01" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Niemeijer et al., &quot;Retinopathy online challenge: Automatic detec- tion of microaneurysms in digital color fundus photographs,&quot; IEEE Trans. Med. Imag., vol. 29, no. 1, pp. 185-195, Jan. 2010.</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Extraction of airways from CT (EXACT&apos;09)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2093" to="2107" />
			<date type="published" when="2012-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Lo et al., &quot;Extraction of airways from CT (EXACT&apos;09),&quot; IEEE Trans. Med. Imag., vol. 31, no. 11, pp. 2093-2107, Nov. 2012.</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">BEaST: Brain extraction based on nonlocal segmentation technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Eskildsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2362" to="2373" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. F. Eskildsen et al., &quot;BEaST: Brain extraction based on nonlocal seg- mentation technique,&quot; Neuroimage, vol. 59, no. 3, pp. 2362-2373, 2012.</note>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Simultaneous truth and performance level estimation (STAPLE): An algorithm for the validation of image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Wells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="903" to="921" />
			<date type="published" when="2004-07" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. K. Warfield, K. H. Zou, and W. M. Wells, &quot;Simultaneous truth and performance level estimation (STAPLE): An algorithm for the valida- tion of image segmentation,&quot; IEEE Trans. Med. Imag., vol. 23, no. 7, pp. 903-921, Jul. 2004.</note>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Statistical validation of image segmentation quality based on a spatial overlap index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="189" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="raw_reference">K. H. Zou et al., &quot;Statistical validation of image segmentation quality based on a spatial overlap index,&quot; Acad. Radiol., vol. 11, no. 2, pp. 178-189, 2004.</note>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">A validation framework for brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Archip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Jolesz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acad. Radiol</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1242" to="1251" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Archip, F. A. Jolesz, and S. K. Warfield, &quot;A validation framework for brain tumor segmentation,&quot; Acad. Radiol., vol. 14, no. 10, pp. 1242-1251, 2007.</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Tumorcut: Segmentation of brain tumors on contrast enhanced MR images for radiosurgery applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamamci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kucuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Unal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="790" to="804" />
			<date type="published" when="2012-03" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Hamamci, N. Kucuk, K. Karaman, K. Engin, and G. Unal, &quot;Tumor- cut: Segmentation of brain tumors on contrast enhanced MR images for radiosurgery applications,&quot; IEEE Trans. Med. Imag., vol. 31, no. 3, pp. 790-804, Mar. 2012.</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">A generative model for brain tumor segmentation in multi-modal images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="151" to="159" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. H. Menze et al., &quot;A generative model for brain tumor segmentation in multi-modal images,&quot; in Proc. MICCAI, 2010, pp. 151-159.</note>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">The ITK Software Guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ibanez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Kitware</publisher>
			<pubPlace>Clifton Park, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">L. Ibanez et al., The ITK Software Guide. Clifton Park, NY: Kitware, 2003.</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">A skull-stripping filter for ITK</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fejes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insight J</title>
		<imprint>
			<biblScope unit="page" from="70" to="78" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer, T. Fejes, and M. Reyes, &quot;A skull-stripping filter for ITK,&quot; Insight J., pp. 70-78, 2012.</note>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Simulation of brain tumors in MR images for evaluation of segmentation efficacy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prastawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gerig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="297" to="311" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Prastawa, E. Bullitt, and G. Gerig, &quot;Simulation of brain tumors in MR images for evaluation of segmentation efficacy,&quot; Med. Image Anal., vol. 13, pp. 297-311, 2009.</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Clatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain tumor growth simulation Tech. Rep</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="raw_reference">O. Clatz et al., Brain tumor growth simulation Tech. Rep., 2004.</note>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Brainweb: Online interface to a 3D MRI simulated brain database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Cocosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kollokian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K S</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Pike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="page" from="301" to="307" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note type="raw_reference">C. A. Cocosco, V. Kollokian, R. K.-S. Kwan, G. B. Pike, and A. C. Evans, &quot;Brainweb: Online interface to a 3D MRI simulated brain data- base,&quot; NeuroImage, pp. 301-307, 1997.</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Twenty new digital brain phantoms for creation of validation image data bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Aubert-Broche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Pike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1410" to="1416" />
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Aubert-Broche, M. Griffin, G. B. Pike, A. C. Evans, and D. L. Collins, &quot;Twenty new digital brain phantoms for creation of valida- tion image data bases,&quot; IEEE Trans. Med. Imag., vol. 25, no. 11, pp. 1410-1416, Nov. 2006.</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">The virtual skeleton database: An open access repository for biomedical research and collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kistler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bonaretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pfahrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Büchler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Internet Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">245</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Kistler, S. Bonaretti, M. Pfahrer, R. Niklaus, and P. Büchler, &quot;The virtual skeleton database: An open access repository for biomedical research and collaboration,&quot; J. Med. Internet Res., vol. 15, no. 11, p. e245, 2013.</note>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Deformable registration of brain tumor images via a statistical model of tumor-induced deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">I</forename><surname>Zacharakib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davatzikos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="752" to="763" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Mohamed, E. I. Zacharakib, D. Shena, and C. Davatzikos, &quot;De- formable registration of brain tumor images via a statistical model of tumor-induced deformation,&quot; Med. Image Anal., vol. 10, pp. 752-763, 2006.</note>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">N4ITK: Nick&apos;s N3 ITK implementation for MRI bias field correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tustison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Insight J</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Tustison and J. Gee, &quot;N4ITK: Nick&apos;s N3 ITK implementation for MRI bias field correction,&quot; Insight J., pp. 1-22, 2010.</note>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>2nd ed</note>
	<note type="raw_reference">T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical Learning, 2nd ed. New York: Springer, 2009.</note>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">On evaluating brain tissue classifiers without a ground truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bouix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1207" to="1224" />
			<date type="published" when="2007-07" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bouix et al., &quot;On evaluating brain tissue classifiers without a ground truth,&quot; Neuroimage, vol. 36, pp. 1207-1224, July 2007.</note>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Multi-modalodal glioblastoma segmentation: Man versus machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Porz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">96873</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Porz et al., &quot;Multi-modalodal glioblastoma segmentation: Man versus machine,&quot; PLOS ONE, vol. 9, p. e96873, 2014.</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Cloud-based research infrastructure for evaluation on big data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Future Internet-Future Internet Assembly, A. E. A. Galis</title>
		<meeting><address><addrLine>Ed. New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="104" to="114" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Hanbury, H. Müller, G. Langs, and B. H. Menze, &quot;Cloud-based research infrastructure for evaluation on big data,&quot; in The Future In- ternet-Future Internet Assembly, A. E. A. Galis, Ed. New York: Springer, 2013, pp. 104-114.</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Segmentation of brain tumor images based on integrated hierarchical classification and regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI-BRATS</title>
		<meeting>MICCAI-BRATS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="32" to="38" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer et al., &quot;Segmentation of brain tumor images based on integrated hierarchical classification and regularization,&quot; in Proc. MICCAI-BRATS, 2012, pp. 32-38.</note>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Performance vs computational efficiency for optimizing single and dynamic MRFs: Setting the state of the art with primal-dual strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tziritas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Paragios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Understand</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Komodakis, G. Tziritas, and N. Paragios, &quot;Performance vs compu- tational efficiency for optimizing single and dynamic MRFs: Setting the state of the art with primal-dual strategies,&quot; Comput. Vis. Image Understand., vol. 112, no. 1, 2008.</note>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Decision forests for classification, regression, density estimation, manifold learning and semi-supervised learning Microsoft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Konukoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. Rep</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Criminisi, J. Shotton, and E. Konukoglu, Decision forests for classi- fication, regression, density estimation, manifold learning and semi-su- pervised learning Microsoft, Tech. Rep., 2011.</note>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">A supervised patchbased approach for human brain labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Habas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Studholme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1852" to="1862" />
			<date type="published" when="2011-10" />
		</imprint>
	</monogr>
	<note type="raw_reference">F. Rousseau, P. A. Habas, and C. Studholme, &quot;A supervised patch- based approach for human brain labeling,&quot; IEEE Trans. Med. Imag., vol. 30, no. 10, pp. 1852-1862, Oct. 2011.</note>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">A review of atlas-based segmentation for magnetic resonance brain images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cabezas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lladó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freixenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Cuadra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="158" to="177" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="raw_reference">M. Cabezas, A. Oliver, X. Lladó, J. Freixenet, and M. B. Cuadra, &quot;A review of atlas-based segmentation for magnetic resonance brain images,&quot; Comput. Methods Programs Biomed., vol. 104, no. 3, pp. e158-e177, 2011.</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Multi-atlas segmentation without registration: A supervoxel-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="535" to="542" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. Wang and P. A. Yushkevich, &quot;Multi-atlas segmentation without reg- istration: A supervoxel-based approach,&quot; in Proc. MICCAI, 2013, pp. 535-542.</note>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Segmentation of MR images via discriminative dictionary learning and sparse coding: Application to hippocampus labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coupé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="page" from="320" to="328" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Tong, R. Wolz, P. Coupé, J. V. Hajnal, and D. Rueckert, &quot;Seg- mentation of MR images via discriminative dictionary learning and sparse coding: Application to hippocampus labeling,&quot; NeuroImage, pp. 320-328, 2013.</note>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Combination strategies in multi-atlas image segmentation: Application to brain MR data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Artaechevarria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Munoz-Barrutia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ortiz-De Solorzano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1266" to="1277" />
			<date type="published" when="2009-08" />
		</imprint>
	</monogr>
	<note type="raw_reference">X. Artaechevarria, A. Munoz-Barrutia, and C. Ortiz-de Solorzano, &quot;Combination strategies in multi-atlas image segmentation: Applica- tion to brain MR data,&quot; IEEE Trans. Med. Imag., vol. 28, no. 8, pp. 1266-1277, Aug. 2009.</note>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Patch-based segmentation using expert priors: Application to hippocampus and ventricle segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coupé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="940" to="954" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Coupé et al., &quot;Patch-based segmentation using expert priors: Appli- cation to hippocampus and ventricle segmentation,&quot; NeuroImage, vol. 54, pp. 940-954, 2011.</note>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Optimal weights for multi-atlas label fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pluta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Altinay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yushkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Inf. Process. Med. Imag</title>
		<meeting>Inf. ess. Med. Imag</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="73" to="84" />
		</imprint>
	</monogr>
	<note type="raw_reference">H. Wang, J. W. Suh, J. Pluta, M. Altinay, and P. Yushkevich, &quot;Optimal weights for multi-atlas label fusion,&quot; in Proc. Inf. Process. Med. Imag., 2011, pp. 73-84.</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Minimizing joint risk of mislabeling for iterative patchbased label fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="551" to="558" />
		</imprint>
	</monogr>
	<note type="raw_reference">G. Wu et al., &quot;Minimizing joint risk of mislabeling for iterative patch- based label fusion,&quot; in Proc. MICCAI, 2013, pp. 551-558.</note>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Decision forests for tissue-specific segmentation of high-grade gliomas in multi-channel MR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. Zikic et al., &quot;Decision forests for tissue-specific segmentation of high-grade gliomas in multi-channel MR,&quot; in Proc. MICCAI, 2012, pp. 369-376.</note>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">An augmented Lagrangian method for total variation video restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Khoshabeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3097" to="3111" />
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. H. Chan, R. Khoshabeh, K. B. Gibson, P. E. Gill, and T. Q. Nguyen, &quot;An augmented Lagrangian method for total variation video restora- tion,&quot; IEEE Trans. Image Process., vol. 20, no. 11, pp. 3097-3111, Nov. 2011.</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">On the statistical analysis of dirty pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc</title>
		<imprint>
			<biblScope unit="page" from="259" to="302" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Besag, &quot;On the statistical analysis of dirty pictures,&quot; J. R. Stat. Soc., pp. 259-302, 1986.</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. R. Stat. Soc</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. P. Dempster, N. M. Laird, and D. B. Rubin, &quot;Maximum likelihood from incomplete data via the EM algorithm,&quot; J. R. Stat. Soc., vol. 39, pp. 1-38, 1977.</note>
</biblStruct>

<biblStruct xml:id="b134">
	<analytic>
		<title level="a" type="main">EM procedures using mean field-like approximations for Markov model-based image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peyrard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="144" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="raw_reference">G. Celeux, F. Forbes, and N. Peyrard, &quot;EM procedures using mean field-like approximations for Markov model-based image segmenta- tion,&quot; Pattern Recognit., vol. 36, no. 1, pp. 131-144, 2003.</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">N4ITK: Improved n3 bias correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Tustison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1310" to="1320" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. J. Tustison et al., &quot;N4ITK: Improved n3 bias correction,&quot; IEEE Trans. Med. Imag., vol. 29, no. 6, pp. 1310-1320, Jun. 2010.</note>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">New variants of a method of MRI scale standardization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Nyúl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Udupa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imag</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="150" />
			<date type="published" when="2000-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. G. Nyúl, J. K. Udupa, and X. Zhang, &quot;New variants of a method of MRI scale standardization,&quot; IEEE Trans. Med. Imag., vol. 19, no. 2, pp. 143-150, Feb. 2000.</note>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">International Society for Optics and Photonics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Laws</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Annu. Tech. Symp</title>
		<meeting>24th Annu. Tech. Symp</meeting>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="page" from="376" to="381" />
		</imprint>
	</monogr>
	<note>Rapid texture identification</note>
	<note type="raw_reference">K. I. Laws, International Society for Optics and Photonics, &quot;Rapid texture identification,&quot; in Proc. 24th Annu. Tech. Symp., 1980, pp. 376-381.</note>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Fully automatic segmentation of brain tumor images using support vector machine classification in combination with hierarchical conditional random field regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Nolte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
	<note type="raw_reference">S. Bauer, L.-P. Nolte, and M. Reyes, &quot;Fully automatic segmentation of brain tumor images using support vector machine classification in com- bination with hierarchical conditional random field regularization,&quot; in Proc. MICCAI, 2011, vol. 14.</note>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Efficacy of texture, shape, and intensity feature fusion for posterior-fossa tumor segmentation in MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Iftekharuddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vossough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Technol. Biomed</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="206" to="213" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. Ahmed, K. M. Iftekharuddin, and A. Vossough, &quot;Efficacy of texture, shape, and intensity feature fusion for posterior-fossa tumor segmen- tation in MRI,&quot; IEEE Trans. Inf. Technol. Biomed., vol. 15, no. 2, pp. 206-213, Feb. 2011.</note>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Multi-fractal texture estimation for detection and segmentation of brain tumors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M S</forename><surname>Reza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Iftekharuddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3204" to="3215" />
			<date type="published" when="2013-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Islam, S. M. S. Reza, and K. M. Iftekharuddin, &quot;Multi-fractal tex- ture estimation for detection and segmentation of brain tumors,&quot; IEEE Trans. Biomed. Eng., vol. 60, no. 11, pp. 3204-3215, Nov. 2013.</note>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Representing and recognizing the visual appearance of materials using three-dimensional textons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="44" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="raw_reference">T. Leung and J. Malik, &quot;Representing and recognizing the visual ap- pearance of materials using three-dimensional textons,&quot; Int. J. Comput. Vis., vol. 43, no. 1, pp. 29-44, 2001.</note>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn. J</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="raw_reference">L. Breiman, &quot;Random forests,&quot; Mach. Learn. J., vol. 45, pp. 5-32, 2001.</note>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Autoencoder in time-series analysis for unsupervised tissues characterisation in a large unlabelled medical image dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Orton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 10th Int. Conf</title>
		<meeting>IEEE 10th Int. Conf</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="259" to="264" />
		</imprint>
	</monogr>
	<note type="raw_reference">H.-C. Shin, M. Orton, D. J. Collins, S. Doran, and M. O. Leach, &quot;Au- toencoder in time-series analysis for unsupervised tissues characterisa- tion in a large unlabelled medical image dataset,&quot; in Proc. IEEE 10th Int. Conf. Mach. Learn. Appl. Workshop, 2011, vol. 1, pp. 259-264.</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">Hybrid clustering and logistic regression for multi-modal brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshops Challanges MICCAI</title>
		<meeting>Workshops Challanges MICCAI</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="raw_reference">H.-C. Shin, &quot;Hybrid clustering and logistic regression for multi-modal brain tumor segmentation,&quot; in Proc. Workshops Challanges MICCAI, 2012.</note>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Orton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Doran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1930" to="1943" />
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
	<note type="raw_reference">H.-C. Shin, M. R. Orton, D. J. Collins, S. J. Doran, and M. O. Leach, &quot;Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 35, no. 8, pp. 1930-1943, Aug. 2013.</note>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Inf. Process. Syst</title>
		<meeting>Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
	<note type="raw_reference">A. Krizhevsky, I. Sutskever, and G. Hinton, &quot;Imagenet classification with deep convolutional neural networks,&quot; in Proc. Neural Inf. Process. Syst., 2012, pp. 1106-1114.</note>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Hierarchical probabilistic Gabor and MRF segmentation of brain tumours in MRI volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Subbanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">8149</biblScope>
			<biblScope unit="page" from="751" to="758" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Subbanna, D. Precup, L. Collins, and T. Arbel, &quot;Hierarchical prob- abilistic Gabor and MRF segmentation of brain tumours in MRI vol- umes,&quot; Proc. MICCAI, vol. 8149, pp. 751-758, 2013.</note>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Probabilistic Gabor and Markov random fields segmentation of brain tumours in MRI volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Subbanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI Brain Tumor Segmentat</title>
		<meeting>MICCAI Brain Tumor Segmentat</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="28" to="31" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Subbanna and T. Arbel, &quot;Probabilistic Gabor and Markov random fields segmentation of brain tumours in MRI volumes,&quot; in Proc. MICCAI Brain Tumor Segmentat. Challenge, 2012, pp. 28-31.</note>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Correction for B(1) and B(0) variations in quantitative T2 measurements using MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sled</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mag. Reson. Med</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="589" to="593" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Sled and G. Pike, &quot;Correction for B(1) and B(0) variations in quan- titative T2 measurements using MRI,&quot; Mag. Reson. Med., vol. 43, no. 4, pp. 589-593, 2000.</note>
</biblStruct>

<biblStruct xml:id="b150">
	<analytic>
		<title level="a" type="main">Automatic 3D intersubject registration of MR volumetric data in standardised talairach space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Neelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comp. Assist. Tom</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="192" to="205" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. L. Collins, P. Neelin, T. M. Peters, and A. C. Evans, &quot;Automatic 3D intersubject registration of MR volumetric data in standardised ta- lairach space,&quot; J. Comp. Assist. Tom., vol. 18, pp. 192-205, 1994.</note>
</biblStruct>

<biblStruct xml:id="b151">
	<analytic>
		<title level="a" type="main">Intensity non-uniformity correction in MRI: Existing methods and their validation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Belaroussia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Millesb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carmec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Benoit-Cattina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Med. Image Anal</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="234" to="246" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. Belaroussia, J. Millesb, S. Carmec, H. Zhua, Y. M. , and Benoit-Cat- tina, &quot;Intensity non-uniformity correction in MRI: Existing methods and their validation,&quot; Med. Image Anal., vol. 10, no. 2, pp. 234-246, 2006.</note>
</biblStruct>

<biblStruct xml:id="b152">
	<analytic>
		<title level="a" type="main">Existence conditions for discrete noncanonical multiwindow Gabor schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Subbanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5113" to="5117" />
			<date type="published" when="2007-10" />
		</imprint>
	</monogr>
	<note type="raw_reference">N. Subbanna and Y. Zeevi, &quot;Existence conditions for discrete non- canonical multiwindow Gabor schemes,&quot; IEEE Trans. Signal Process., vol. 55, no. 10, pp. 5113-5117, Oct. 2007.</note>
</biblStruct>

<biblStruct xml:id="b153">
	<analytic>
		<title level="a" type="main">The case for open computer programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham-Cumming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">482</biblScope>
			<biblScope unit="issue">7386</biblScope>
			<biblScope unit="page" from="485" to="488" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">D. C. Ince, L. Hatton, and J. Graham-Cumming, &quot;The case for open computer programs,&quot; Nature, vol. 482, no. 7386, pp. 485-488, Feb. 2012.</note>
</biblStruct>

<biblStruct xml:id="b154">
	<analytic>
		<title level="a" type="main">The optimal template effect in hippocampus studies of diseased populations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2457" to="2466" />
			<date type="published" when="2010-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. B. Avants et al., &quot;The optimal template effect in hippocampus studies of diseased populations,&quot; Neuroimage, vol. 49, no. 3, pp. 2457-2466, Feb. 2010.</note>
</biblStruct>

<biblStruct xml:id="b155">
	<analytic>
		<title level="a" type="main">Multi-parametric neuroimaging reproducibility: A 3-T resource study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Landman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2854" to="66" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. A. Landman et al., &quot;Multi-parametric neuroimaging reproducibility: A 3-T resource study,&quot; Neuroimage, vol. 54, no. 4, pp. 2854-66, Feb. 2011.</note>
</biblStruct>

<biblStruct xml:id="b156">
	<analytic>
		<title level="a" type="main">An open source multivariate framework for n-tissue segmentation with evaluation on public data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Tustison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Gee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="400" />
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. B. Avants, N. J. Tustison, J. Wu, P. A. Cook, and J. C. Gee, &quot;An open source multivariate framework for n-tissue segmentation with evalua- tion on public data,&quot; Neuroinformatics, vol. 9, no. 4, pp. 381-400, Dec. 2011.</note>
</biblStruct>

<biblStruct xml:id="b157">
	<analytic>
		<title level="a" type="main">A reproducible evaluation of ANTs similarity metric performance in brain image registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Avants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2033" to="2077" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
	<note type="raw_reference">B. B. Avants et al., &quot;A reproducible evaluation of ANTs similarity metric performance in brain image registration,&quot; Neuroimage, vol. 54, no. 3, pp. 2033-44, Feb. 2011.</note>
</biblStruct>

<biblStruct xml:id="b158">
	<analytic>
		<title level="a" type="main">An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1124" to="1137" />
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Boykov and V. Kolmogorov, &quot;An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 26, no. 9, pp. 1124-1137, Sep. 2004.</note>
</biblStruct>

<biblStruct xml:id="b159">
	<analytic>
		<title level="a" type="main">What energy functions can be minimized via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="147" to="159" />
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
	<note type="raw_reference">V. Kolmogorov and R. Zabih, &quot;What energy functions can be mini- mized via graph cuts,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 26, no. 12, pp. 147-159, Dec. 2004.</note>
</biblStruct>

<biblStruct xml:id="b160">
	<analytic>
		<title level="a" type="main">Efficient approximate energy minimization via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001-12" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Y. Boykov and O. Veksler, &quot;Efficient approximate energy minimiza- tion via graph cuts,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 20, no. 12, pp. 1222-1239, Dec. 2001.</note>
</biblStruct>

<biblStruct xml:id="b161">
	<analytic>
		<title level="a" type="main">Susan-A new approach to low level image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Brady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="45" to="78" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note type="raw_reference">S. M. Smith and J. M. Brady, &quot;Susan-A new approach to low level image processing,&quot; Int. J. Comput. Vis., vol. 23, pp. 45-78, 1997.</note>
</biblStruct>

<biblStruct xml:id="b162">
	<analytic>
		<title level="a" type="main">SLIC superpixels compared to state-of-the-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2274" to="2282" />
			<date type="published" when="2012-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">R. Achanta et al., &quot;SLIC superpixels compared to state-of-the-art su- perpixel methods,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 11, pp. 2274-2282, Nov. 2012.</note>
</biblStruct>

<biblStruct xml:id="b163">
	<analytic>
		<title level="a" type="main">Efficient approximate energy minimization via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001-11" />
		</imprint>
	</monogr>
	<note type="raw_reference">Y. Boykov, O. Veksler, and R. Zabih, &quot;Efficient approximate energy minimization via graph cuts,&quot; IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 11, pp. 1222-1239, Nov. 2001.</note>
</biblStruct>

<biblStruct xml:id="b164">
	<analytic>
		<title level="a" type="main">Real-time human pose recognition in parts from a single depth image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recongnit</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recongnit</meeting>
		<imprint>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
	<note type="raw_reference">J. Shotton et al., &quot;Real-time human pose recognition in parts from a single depth image,&quot; Proc. IEEE Conf. Comput. Vis. Pattern Recon- gnit., pp. 1297-1304, Jun. 2011.</note>
</biblStruct>

<biblStruct xml:id="b165">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="raw_reference">P. Viola and M. J. Jones, &quot;Robust real-time face detection,&quot; Int. J. Comput. Vis., vol. 57, no. 2, pp. 137-154, 2004.</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
